{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qspqbJOVOpN-"
      },
      "source": [
        "## Equivaraint TD3 Actor and QNetwork Test (JAX Implementation)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCUFxefFNgfT",
        "outputId": "f5da9bd2-74eb-46ad-8a91-6c445d15a0c5"
      },
      "outputs": [],
      "source": [
        "# Install necessary packages\n",
        "#%pip install -q  gymnasium[mujoco] jax jaxlib flax optax tyro stable-baselines3 torch tensorboard emlp\n",
        "#%pip install graphviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b0g6BMztPLnM"
      },
      "outputs": [],
      "source": [
        "# Importing the nessesary packages for the entire code\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "import gymnasium as gym\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from emlp.groups import SO, C, D, Trivial, Group, O\n",
        "from emlp.nn.flax import EMLPBlock, Linear, uniform_rep, EMLP, Sequential\n",
        "from emlp.reps import Scalar, Vector, Rep, T\n",
        "from typing import Callable\n",
        "import torch\n",
        "from flax.training.train_state import TrainState\n",
        "import optax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOI6ZRJYQdiQ"
      },
      "source": [
        "## The standard networks and their equivaraint version using the emlp package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WAAvBhj-Pq-b"
      },
      "outputs": [],
      "source": [
        "class QNetwork(nn.Module):\n",
        "    ch: int = 128\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x: jnp.ndarray, a: jnp.ndarray):\n",
        "        x = jnp.concatenate([x, a], -1)\n",
        "        x = nn.Dense(self.ch)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(self.ch)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(1)(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class InvariantQNetwork(nn.Module):\n",
        "    rep_in: Callable\n",
        "    rep_out: Callable\n",
        "    group: Callable\n",
        "    ch: int = 128\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x, a):\n",
        "        rep_in = self.rep_in(self.group)\n",
        "        rep_out = self.rep_out(self.group)\n",
        "        middle_layers = uniform_rep(self.ch, self.group)\n",
        "        print(\"Middle layers: \", middle_layers)\n",
        "        x = jnp.concatenate([x, a], axis=1)\n",
        "        network = Sequential(\n",
        "            EMLPBlock(rep_in=rep_in, rep_out=middle_layers),\n",
        "            EMLPBlock(rep_in=middle_layers, rep_out=middle_layers),\n",
        "            Linear(middle_layers, rep_out),\n",
        "        )\n",
        "\n",
        "        return network(x)\n",
        "\n",
        "\n",
        "class Actor(nn.Module):\n",
        "    action_dim: int\n",
        "    action_scale: jnp.ndarray\n",
        "    action_bias: jnp.ndarray\n",
        "    ch: int = 256\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        x = nn.Dense(self.ch)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(self.ch)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(self.action_dim)(x)\n",
        "        x = nn.tanh(x)\n",
        "        x = x * self.action_scale + self.action_bias\n",
        "        return x\n",
        "\n",
        "\n",
        "class EquiActor(nn.Module):\n",
        "    rep_in: Callable\n",
        "    rep_out: Callable\n",
        "    group: Callable\n",
        "    action_scale: jnp.ndarray\n",
        "    action_bias: jnp.ndarray\n",
        "    ch: int = 384\n",
        "    num_layers: int = 3\n",
        "\n",
        "    def setup(self):\n",
        "        # Instantiate the EMLP model only once during setup\n",
        "        self.emlp_model = EMLP(\n",
        "            rep_in=self.rep_in,\n",
        "            rep_out=self.rep_out,\n",
        "            group=self.group,\n",
        "            ch=self.ch,\n",
        "            num_layers=self.num_layers\n",
        "        )\n",
        "\n",
        "    def __call__(self, x):\n",
        "        # Pass the input through the EMLP model\n",
        "        x = self.emlp_model(x)\n",
        "        \n",
        "        # # Apply the final transformation (tanh, scaling, and bias)\n",
        "        # x = jax.nn.tanh(x)\n",
        "        # x = x * self.action_scale\n",
        "        # x = x + self.action_bias\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IpbxZd_YZUZ"
      },
      "source": [
        "## Representation for reflection across the vecrtical axis for the action in inverted pendulum enviroment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "DB8mF8pCX3Uc"
      },
      "outputs": [],
      "source": [
        "class InvertedPendulumActionRep(Rep):\n",
        "    \"\"\"Representation for reflection across the vecrtical axis for the action in inverted pendulum enviroment.\"\"\"\n",
        "\n",
        "    def __init__(self, G):\n",
        "        self.G = G  # The group to which this representation is associated\n",
        "        self.is_permutation = True\n",
        "        super().__init__()\n",
        "    def rho(self, M):\n",
        "        \"\"\"\n",
        "        Group representation of the matrix M.\n",
        "        M should be either the identity or reflection matrix.\n",
        "        \"\"\"\n",
        "        if jnp.allclose(M, jnp.eye(2)):\n",
        "            return jnp.eye(1)  # Identity matrix, no change\n",
        "        elif jnp.allclose(M, jnp.array([[-1, 0], [0, -1]])):\n",
        "            return -1*jnp.eye(1)   # Sign flip for action\n",
        "        else:\n",
        "            raise ValueError(\"Unrecognized group element\")\n",
        "\n",
        "    def size(self):\n",
        "        assert self.G is not None, f\"must know G to find size for rep={self}\"\n",
        "        return 1\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"InvertedPendulumActionRep\"\n",
        "    def __call__(self,G):\n",
        "        return self.__class__(G)\n",
        "    \n",
        "class GroupOfOneReflection(Group):\n",
        "    \"\"\" The Orthogonal group O(n) in n dimensions\"\"\"\n",
        "    def __init__(self,n):\n",
        "        #self.is_permutation = True\n",
        "        self.discrete_generators = np.eye(n)[None]\n",
        "        self.discrete_generators[0,0,0]=-1\n",
        "        print(self.discrete_generators)\n",
        "        super().__init__(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9X5-kIaXJ_l"
      },
      "source": [
        "## Testing Equivaraince Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jxJIr_qNXVEQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Middle layers:  30V⁰+15V+7V²+3V³+V⁴\n",
            "Middle layers:  30V⁰+15V+7V²+3V³+V⁴\n"
          ]
        }
      ],
      "source": [
        "G = O(2)\n",
        "env_id = \"InvertedPendulum-v4\"\n",
        "# Create the state and action representations\n",
        "envs = gym.make(env_id)\n",
        "envs.observation_space.dtype = np.float64\n",
        "\n",
        "obs,_ = envs.reset()\n",
        "key = jax.random.PRNGKey(1)\n",
        "\n",
        "class TrainState(TrainState):\n",
        "    target_params: flax.core.FrozenDict\n",
        "\n",
        "repin_actor = 2*Vector(G)\n",
        "repout_actor = Scalar(G)\n",
        "\n",
        "repin_q = 2*Vector(G)+ InvertedPendulumActionRep(G)\n",
        "repout_q = Scalar(G)\n",
        "\n",
        "actor = EquiActor(\n",
        "    action_scale=jnp.array(\n",
        "        (envs.action_space.high - envs.action_space.low) / 2.0\n",
        "    ),\n",
        "    action_bias=jnp.array(\n",
        "        (envs.action_space.high + envs.action_space.low) / 2.0\n",
        "    ),\n",
        "    rep_in=repin_actor,\n",
        "    rep_out=repout_actor,\n",
        "    group=G,\n",
        "    ch=128,\n",
        ")\n",
        "qf = InvariantQNetwork(rep_in=repin_q, rep_out=repout_q, group=G, ch=128)\n",
        "\n",
        "key, actor_key, expert_actor_key, qf_key = jax.random.split(key, 4)\n",
        "\n",
        "actor_state = TrainState.create(\n",
        "    apply_fn=actor.apply,\n",
        "    params=actor.init(actor_key, obs),\n",
        "    target_params=actor.init(actor_key, obs),\n",
        "    tx=optax.adam(learning_rate=1e-3),\n",
        ")\n",
        "\n",
        "qf_state = TrainState.create(\n",
        "    apply_fn=qf.apply,\n",
        "    params=qf.init(qf_key, obs.reshape(1,-1), envs.action_space.sample().reshape(1,-1)),\n",
        "    target_params=qf.init(qf_key, obs.reshape(1,-1), envs.action_space.sample().reshape(1,-1)),\n",
        "    tx=optax.adam(learning_rate=1e-3),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HtsauCxQZKXH"
      },
      "outputs": [],
      "source": [
        "def rel_err(a, b):\n",
        "    return np.array(\n",
        "        jnp.sqrt(((a - b) ** 2).mean())\n",
        "        / (jnp.sqrt((a**2).mean()) + jnp.sqrt((b**2).mean()))\n",
        "    )\n",
        "\n",
        "# equivaraince error function for the actor network\n",
        "def equivariance_err_actor(model, params, state, rin, rout, G):\n",
        "    gs = G.samples(5)\n",
        "    rho_gin = jnp.stack([jnp.array(rin.rho_dense(g)) for g in gs])\n",
        "    rho_gout = jnp.stack([jnp.array(rout.rho_dense(g)) for g in gs])\n",
        "    y1 = model.apply(params, (rho_gin @ state[..., None]).squeeze(-1))\n",
        "    y2 = model.apply(params, state)\n",
        "    y2 = (rho_gout @ y2[..., None]).squeeze(-1)\n",
        "    error = rel_err(y1, y2)\n",
        "    print(\"Equivariance error:\", error)\n",
        "    return error\n",
        "\n",
        "\n",
        "# equivaraince error function for Q Network\n",
        "def equivariance_err_qvalue(model, params, state, actions, rin, rout, G):\n",
        "    gs = G.samples(5)\n",
        "    rho_gin = jnp.stack([jnp.array(rin.rho_dense(g)) for g in gs])\n",
        "    rho_gout = jnp.stack([jnp.array(rout.rho_dense(g)) for g in gs])\n",
        "    x = jnp.concatenate([state, actions], axis=1)\n",
        "    x = (rho_gin @ x[..., None]).squeeze(-1)\n",
        "    y1 = model.apply(params, x[:, :state.shape[-1]], x[:,-actions.shape[-1]:])\n",
        "    y2 = model.apply(params, state, actions)\n",
        "    y2 = (rho_gout @ y2[..., None]).squeeze(-1)\n",
        "    error = rel_err(y1, y2)\n",
        "    print(\"Equivariance error:\", error)\n",
        "    return error\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aSHpjNfZGFY",
        "outputId": "eda5e3cd-5a30-4bb1-d615-725f0ae1010c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Equivariance error: 0.14416994\n",
            "\n"
          ]
        }
      ],
      "source": [
        "equiv_error =  equivariance_err_actor(\n",
        "                        actor, actor_state.params, obs.reshape(1,-1), repin_actor, repout_actor, G\n",
        "                    )\n",
        "print()\n",
        "# action = actor.apply(actor_state.params, obs)\n",
        "# equiv_error =  equivariance_err_qvalue(\n",
        "#                         qf, qf_state.params, obs.reshape(1,-1), action.reshape(1,-1),repin_q, repout_q, G\n",
        "#                     )\n",
        "\n",
        "#print(actor.tabulate(jax.random.PRNGKey(0), obs))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Equivariance error: 1.6587154e-07\n"
          ]
        }
      ],
      "source": [
        "from jax import random\n",
        "import numpy as np\n",
        "import emlp.nn.flax as nn # import from the flax implementation\n",
        "from emlp.reps import T,V, Scalar # Import the representations we need\n",
        "from emlp.groups import SO, C, D, Trivial, Group, O\n",
        "\n",
        "\n",
        "x = np.random.randn(1,repin_actor(G).size()) # generate some random data\n",
        "\n",
        "model = nn.EMLP(repin_actor(G),repout_actor(G),G, ch=128, num_layers=2) # Create an equivariant model\n",
        "\n",
        "key = random.PRNGKey(0)\n",
        "params = model.init(random.PRNGKey(42), obs)\n",
        "\n",
        "y = model.apply(params,  obs) # Forward pass with inputs x and parameters\n",
        "\n",
        "equivariance_err_actor(\n",
        "                        model, params, obs, repin_actor, repout_actor, G\n",
        "                    )\n",
        "middle_layers = 1*[uniform_rep(128,G)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                     _Sequential Summary                                     </span>\n",
              "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> path             </span>┃<span style=\"font-weight: bold\"> module            </span>┃<span style=\"font-weight: bold\"> inputs         </span>┃<span style=\"font-weight: bold\"> outputs        </span>┃<span style=\"font-weight: bold\"> params           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
              "│                  │ _Sequential       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,4]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1]   │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_0        │ _EMLPBlock        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,4]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_0/linear │ _Linear           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,4]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ b: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[154]  │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[154,4]   │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">770 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(3.1 KB)</span>     │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_0/bilin… │ _BiLinear         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ w: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[9285] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">9,285 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(37.1 KB)</span>  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_0/nonli… │ GatedNonlinearity │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_1        │ _EMLPBlock        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_1/linear │ _Linear           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ b: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[154]  │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[154,128] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">19,866 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(79.5 KB)</span> │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_1/bilin… │ _BiLinear         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ w: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[9285] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">9,285 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(37.1 KB)</span>  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_1/nonli… │ GatedNonlinearity │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_2        │ _Linear           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1]   │ b: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1]    │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128]   │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(516 B)</span>      │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│<span style=\"font-weight: bold\">                  </span>│<span style=\"font-weight: bold\">                   </span>│<span style=\"font-weight: bold\">                </span>│<span style=\"font-weight: bold\">          Total </span>│<span style=\"font-weight: bold\"> 39,335 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(157.3 </span><span style=\"font-weight: bold\">   </span>│\n",
              "│<span style=\"font-weight: bold\">                  </span>│<span style=\"font-weight: bold\">                   </span>│<span style=\"font-weight: bold\">                </span>│<span style=\"font-weight: bold\">                </span>│<span style=\"font-weight: bold\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">KB)</span><span style=\"font-weight: bold\">              </span>│\n",
              "└──────────────────┴───────────────────┴────────────────┴────────────────┴──────────────────┘\n",
              "<span style=\"font-weight: bold\">                                                                                             </span>\n",
              "<span style=\"font-weight: bold\">                             Total Parameters: 39,335 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(157.3 KB)</span><span style=\"font-weight: bold\">                             </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                                     _Sequential Summary                                     \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mpath            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
              "│                  │ _Sequential       │ \u001b[2mfloat32\u001b[0m[1,4]   │ \u001b[2mfloat32\u001b[0m[1,1]   │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_0        │ _EMLPBlock        │ \u001b[2mfloat32\u001b[0m[1,4]   │ \u001b[2mfloat32\u001b[0m[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_0/linear │ _Linear           │ \u001b[2mfloat32\u001b[0m[1,4]   │ \u001b[2mfloat32\u001b[0m[1,154] │ b: \u001b[2mfloat32\u001b[0m[154]  │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ \u001b[2mfloat32\u001b[0m[154,4]   │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m770 \u001b[0m\u001b[1;2m(3.1 KB)\u001b[0m     │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_0/bilin… │ _BiLinear         │ \u001b[2mfloat32\u001b[0m[1,154] │ \u001b[2mfloat32\u001b[0m[1,154] │ w: \u001b[2mfloat32\u001b[0m[9285] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m9,285 \u001b[0m\u001b[1;2m(37.1 KB)\u001b[0m  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_0/nonli… │ GatedNonlinearity │ \u001b[2mfloat32\u001b[0m[1,154] │ \u001b[2mfloat32\u001b[0m[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_1        │ _EMLPBlock        │ \u001b[2mfloat32\u001b[0m[1,128] │ \u001b[2mfloat32\u001b[0m[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_1/linear │ _Linear           │ \u001b[2mfloat32\u001b[0m[1,128] │ \u001b[2mfloat32\u001b[0m[1,154] │ b: \u001b[2mfloat32\u001b[0m[154]  │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ \u001b[2mfloat32\u001b[0m[154,128] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m19,866 \u001b[0m\u001b[1;2m(79.5 KB)\u001b[0m │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_1/bilin… │ _BiLinear         │ \u001b[2mfloat32\u001b[0m[1,154] │ \u001b[2mfloat32\u001b[0m[1,154] │ w: \u001b[2mfloat32\u001b[0m[9285] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m9,285 \u001b[0m\u001b[1;2m(37.1 KB)\u001b[0m  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_1/nonli… │ GatedNonlinearity │ \u001b[2mfloat32\u001b[0m[1,154] │ \u001b[2mfloat32\u001b[0m[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ modules_2        │ _Linear           │ \u001b[2mfloat32\u001b[0m[1,128] │ \u001b[2mfloat32\u001b[0m[1,1]   │ b: \u001b[2mfloat32\u001b[0m[1]    │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ \u001b[2mfloat32\u001b[0m[1,128]   │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m129 \u001b[0m\u001b[1;2m(516 B)\u001b[0m      │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│\u001b[1m \u001b[0m\u001b[1m                \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m39,335 \u001b[0m\u001b[1;2m(157.3 \u001b[0m\u001b[1m  \u001b[0m\u001b[1m \u001b[0m│\n",
              "│\u001b[1m                  \u001b[0m│\u001b[1m                   \u001b[0m│\u001b[1m                \u001b[0m│\u001b[1m                \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2mKB)\u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\n",
              "└──────────────────┴───────────────────┴────────────────┴────────────────┴──────────────────┘\n",
              "\u001b[1m                                                                                             \u001b[0m\n",
              "\u001b[1m                             Total Parameters: 39,335 \u001b[0m\u001b[1;2m(157.3 KB)\u001b[0m\u001b[1m                             \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                      EquiActor Summary                                      </span>\n",
              "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> path             </span>┃<span style=\"font-weight: bold\"> module            </span>┃<span style=\"font-weight: bold\"> inputs         </span>┃<span style=\"font-weight: bold\"> outputs        </span>┃<span style=\"font-weight: bold\"> params           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
              "│                  │ EquiActor         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,4]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1]   │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model       │ _Sequential       │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,4]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1]   │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _EMLPBlock        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,4]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _Linear           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,4]   │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ b: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[154]  │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[154,4]   │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">770 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(3.1 KB)</span>     │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _BiLinear         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ w: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[9285] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">9,285 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(37.1 KB)</span>  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ GatedNonlinearity │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _EMLPBlock        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _Linear           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ b: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[154]  │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[154,128] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">19,866 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(79.5 KB)</span> │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _BiLinear         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ w: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[9285] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">9,285 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(37.1 KB)</span>  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ GatedNonlinearity │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _EMLPBlock        │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _Linear           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ b: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[154]  │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[154,128] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">19,866 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(79.5 KB)</span> │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _BiLinear         │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ w: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[9285] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">9,285 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(37.1 KB)</span>  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ GatedNonlinearity │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,154] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _Linear           │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128] │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,1]   │ b: <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1]    │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">float32</span>[1,128]   │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ <span style=\"font-weight: bold\">129 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(516 B)</span>      │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│<span style=\"font-weight: bold\">                  </span>│<span style=\"font-weight: bold\">                   </span>│<span style=\"font-weight: bold\">                </span>│<span style=\"font-weight: bold\">          Total </span>│<span style=\"font-weight: bold\"> 68,486 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(273.9 </span><span style=\"font-weight: bold\">   </span>│\n",
              "│<span style=\"font-weight: bold\">                  </span>│<span style=\"font-weight: bold\">                   </span>│<span style=\"font-weight: bold\">                </span>│<span style=\"font-weight: bold\">                </span>│<span style=\"font-weight: bold\"> </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">KB)</span><span style=\"font-weight: bold\">              </span>│\n",
              "└──────────────────┴───────────────────┴────────────────┴────────────────┴──────────────────┘\n",
              "<span style=\"font-weight: bold\">                                                                                             </span>\n",
              "<span style=\"font-weight: bold\">                             Total Parameters: 68,486 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; font-weight: bold\">(273.9 KB)</span><span style=\"font-weight: bold\">                             </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[3m                                      EquiActor Summary                                      \u001b[0m\n",
              "┏━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mpath            \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodule           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1minputs        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1moutputs       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mparams          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
              "│                  │ EquiActor         │ \u001b[2mfloat32\u001b[0m[1,4]   │ \u001b[2mfloat32\u001b[0m[1,1]   │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model       │ _Sequential       │ \u001b[2mfloat32\u001b[0m[1,4]   │ \u001b[2mfloat32\u001b[0m[1,1]   │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _EMLPBlock        │ \u001b[2mfloat32\u001b[0m[1,4]   │ \u001b[2mfloat32\u001b[0m[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _Linear           │ \u001b[2mfloat32\u001b[0m[1,4]   │ \u001b[2mfloat32\u001b[0m[1,154] │ b: \u001b[2mfloat32\u001b[0m[154]  │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ \u001b[2mfloat32\u001b[0m[154,4]   │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m770 \u001b[0m\u001b[1;2m(3.1 KB)\u001b[0m     │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _BiLinear         │ \u001b[2mfloat32\u001b[0m[1,154] │ \u001b[2mfloat32\u001b[0m[1,154] │ w: \u001b[2mfloat32\u001b[0m[9285] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m9,285 \u001b[0m\u001b[1;2m(37.1 KB)\u001b[0m  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ GatedNonlinearity │ \u001b[2mfloat32\u001b[0m[1,154] │ \u001b[2mfloat32\u001b[0m[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _EMLPBlock        │ \u001b[2mfloat32\u001b[0m[1,128] │ \u001b[2mfloat32\u001b[0m[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _Linear           │ \u001b[2mfloat32\u001b[0m[1,128] │ \u001b[2mfloat32\u001b[0m[1,154] │ b: \u001b[2mfloat32\u001b[0m[154]  │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ \u001b[2mfloat32\u001b[0m[154,128] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m19,866 \u001b[0m\u001b[1;2m(79.5 KB)\u001b[0m │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _BiLinear         │ \u001b[2mfloat32\u001b[0m[1,154] │ \u001b[2mfloat32\u001b[0m[1,154] │ w: \u001b[2mfloat32\u001b[0m[9285] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m9,285 \u001b[0m\u001b[1;2m(37.1 KB)\u001b[0m  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ GatedNonlinearity │ \u001b[2mfloat32\u001b[0m[1,154] │ \u001b[2mfloat32\u001b[0m[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _EMLPBlock        │ \u001b[2mfloat32\u001b[0m[1,128] │ \u001b[2mfloat32\u001b[0m[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _Linear           │ \u001b[2mfloat32\u001b[0m[1,128] │ \u001b[2mfloat32\u001b[0m[1,154] │ b: \u001b[2mfloat32\u001b[0m[154]  │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ \u001b[2mfloat32\u001b[0m[154,128] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m19,866 \u001b[0m\u001b[1;2m(79.5 KB)\u001b[0m │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _BiLinear         │ \u001b[2mfloat32\u001b[0m[1,154] │ \u001b[2mfloat32\u001b[0m[1,154] │ w: \u001b[2mfloat32\u001b[0m[9285] │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m9,285 \u001b[0m\u001b[1;2m(37.1 KB)\u001b[0m  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ GatedNonlinearity │ \u001b[2mfloat32\u001b[0m[1,154] │ \u001b[2mfloat32\u001b[0m[1,128] │                  │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│ emlp_model/modu… │ _Linear           │ \u001b[2mfloat32\u001b[0m[1,128] │ \u001b[2mfloat32\u001b[0m[1,1]   │ b: \u001b[2mfloat32\u001b[0m[1]    │\n",
              "│                  │                   │                │                │ w:               │\n",
              "│                  │                   │                │                │ \u001b[2mfloat32\u001b[0m[1,128]   │\n",
              "│                  │                   │                │                │                  │\n",
              "│                  │                   │                │                │ \u001b[1m129 \u001b[0m\u001b[1;2m(516 B)\u001b[0m      │\n",
              "├──────────────────┼───────────────────┼────────────────┼────────────────┼──────────────────┤\n",
              "│\u001b[1m \u001b[0m\u001b[1m                \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m                 \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m              \u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m         Total\u001b[0m\u001b[1m \u001b[0m│\u001b[1m \u001b[0m\u001b[1m68,486 \u001b[0m\u001b[1;2m(273.9 \u001b[0m\u001b[1m  \u001b[0m\u001b[1m \u001b[0m│\n",
              "│\u001b[1m                  \u001b[0m│\u001b[1m                   \u001b[0m│\u001b[1m                \u001b[0m│\u001b[1m                \u001b[0m│\u001b[1m \u001b[0m\u001b[1;2mKB)\u001b[0m\u001b[1m             \u001b[0m\u001b[1m \u001b[0m│\n",
              "└──────────────────┴───────────────────┴────────────────┴────────────────┴──────────────────┘\n",
              "\u001b[1m                                                                                             \u001b[0m\n",
              "\u001b[1m                             Total Parameters: 68,486 \u001b[0m\u001b[1;2m(273.9 KB)\u001b[0m\u001b[1m                             \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.tabulate(jax.random.PRNGKey(0), x, console_kwargs={'force_terminal': True, 'force_jupyter': True}))\n",
        "\n",
        "print(actor.tabulate(jax.random.PRNGKey(0), x, console_kwargs={'force_terminal': True, 'force_jupyter': True}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class InvaraintQNetwork(nn.Module):\n",
        "    def __init__(self, env, rep_in, rep_out, group, ch=256):\n",
        "        super().__init__()\n",
        "        self.rep_in = rep_in(group)\n",
        "        self.rep_out = rep_out(group)\n",
        "        self.G = group\n",
        "\n",
        "        self.middle_layers = uniform_rep(ch, group)\n",
        "\n",
        "        self.network = nn.Sequential(\n",
        "            EMLPBlock(rep_in=rep_in, rep_out= self.middle_layers),\n",
        "            EMLPBlock(rep_in= self.middle_layers, rep_out= self.middle_layers),\n",
        "            Linear( self.middle_layers, self.rep_out)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, a):\n",
        "        x = torch.cat([x, a], dim=1)\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "class EquiActor(nn.Module):\n",
        "    def __init__(self, env, rep_in, rep_out, group, ch=256):\n",
        "        super().__init__()\n",
        "        self.rep_in = rep_in(group)\n",
        "        self.rep_out = rep_out(group)\n",
        "        self.G = group\n",
        "\n",
        "        self.middle_layers = uniform_rep(ch, group)\n",
        "\n",
        "        self.fc_mu = nn.Sequential(\n",
        "            EMLPBlock(rep_in=rep_in, rep_out= self.middle_layers),\n",
        "            EMLPBlock(rep_in= self.middle_layers, rep_out= self.middle_layers),\n",
        "            Linear( self.middle_layers, self.rep_out)\n",
        "        ).to('cuda')\n",
        "    def forward(self, x):\n",
        "        return torch.tanh(self.fc_mu(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rel_err(a, b):\n",
        "    return torch.sqrt(((a - b) ** 2).mean()) / (torch.sqrt((a ** 2).mean()) + torch.sqrt((b ** 2).mean()))\n",
        "\n",
        "def equivariance_err_actor(model, input, rin, rout, G):\n",
        "    print(input.shape[0])\n",
        "    gs = G.samples(5)\n",
        "    print(gs)\n",
        "    rho_gin = torch.stack([torch.tensor(np.array(rin.rho_dense(g))) for g in gs]).to(input.device)\n",
        "    rho_gout = torch.stack([torch.tensor(np.array(rout.rho_dense(g))) for g in gs]).to(input.device)\n",
        "    y1= model((input[...,None] @ rho_gin ).squeeze(-1)).to(input.device)\n",
        "    print(\"y(rho(g)*x) = \\n\", y1)\n",
        "    y2 = model(input).to(input.device)\n",
        "    y2 = (rho_gout @ y2.unsqueeze(-1)).squeeze(-1)\n",
        "    print(\"rho(g)*y(x) = \\n\", y2)\n",
        "    return rel_err(y1, y2).item()\n",
        "\n",
        "def equivariance_err_value(model, input, rin, rout, G):\n",
        "    print(input.shape[0])\n",
        "    gs = G.samples(5)\n",
        "    print(gs)\n",
        "    rho_gin = torch.stack([torch.tensor(np.array(rin.rho_dense(g))) for g in gs]).to(input.device)\n",
        "    rho_gout = torch.stack([torch.tensor(np.array(rout.rho_dense(g))) for g in gs]).to(input.device)\n",
        "    y1 = model.get_value((rho_gin @ input.unsqueeze(-1)).squeeze(-1))\n",
        "    print(\"y(rho(g)*x) = \\n\", y1)\n",
        "    y2 = (rho_gout @ model.get_value(input).unsqueeze(-1)).squeeze(-1)\n",
        "    print(\"rho(g)*y(x) = \\n\", y2)\n",
        "    return rel_err(y1, y2).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "State Rep: 4\n",
            "Output size: torch.Size([1, 4])\n",
            "1\n",
            "[[[ 1.0000000e+00  9.7971748e-16]\n",
            "  [-9.7971748e-16  1.0000000e+00]]\n",
            "\n",
            " [[-1.0000000e+00 -8.5725277e-16]\n",
            "  [ 8.5725277e-16 -1.0000000e+00]]\n",
            "\n",
            " [[ 1.0000000e+00 -9.7971748e-16]\n",
            "  [ 9.7971748e-16  1.0000000e+00]]\n",
            "\n",
            " [[-1.0000000e+00  8.5725277e-16]\n",
            "  [-8.5725277e-16 -1.0000000e+00]]\n",
            "\n",
            " [[-1.0000000e+00  6.1232340e-16]\n",
            "  [-6.1232340e-16 -1.0000000e+00]]]\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected size for first two dimensions of batch2 tensor to be: [5, 1] but got: [5, 4].",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, state_rep\u001b[38;5;241m.\u001b[39msize())\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m equiv_error \u001b[38;5;241m=\u001b[39m \u001b[43mequivariance_err_actor\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEquivariance Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mequiv_error\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# equiv_error = equivariance_err_value(agent,x, state_rep, value_rep, G)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(f\"Equivariance Error: {equiv_error:.2e}\")\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[11], line 10\u001b[0m, in \u001b[0;36mequivariance_err_actor\u001b[0;34m(model, input, rin, rout, G)\u001b[0m\n\u001b[1;32m      8\u001b[0m rho_gin \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(rin\u001b[38;5;241m.\u001b[39mrho_dense(g))) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m gs])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m      9\u001b[0m rho_gout \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(rout\u001b[38;5;241m.\u001b[39mrho_dense(g))) \u001b[38;5;28;01mfor\u001b[39;00m g \u001b[38;5;129;01min\u001b[39;00m gs])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 10\u001b[0m y1\u001b[38;5;241m=\u001b[39m model((\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrho_gin\u001b[49m )\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my(rho(g)*x) = \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, y1)\n\u001b[1;32m     12\u001b[0m y2 \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;28minput\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected size for first two dimensions of batch2 tensor to be: [5, 1] but got: [5, 4]."
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from emlp.reps import Vector, Scalar\n",
        "import numpy as np\n",
        "from emlp.nn import uniform_rep\n",
        "from emlp.nn.pytorch import EMLPBlock, Linear\n",
        "from emlp.groups import SO, C, D, Trivial, Group, O\n",
        "G = C(2)\n",
        "state_rep = Vector(G) + Vector(G)\n",
        "action_rep = InvertedPendulumActionRep(G)\n",
        "value_rep = Scalar(G)\n",
        "envs = gym.make('Reacher-v4')\n",
        "print(f\"State Rep: {state_rep.size()}\")\n",
        "agent = EquiActor(envs, state_rep, action_rep, G).to('cuda')\n",
        "x = torch.randn(1, state_rep.size()).to('cuda')\n",
        "print(f\"Output size: {x.size()}\")\n",
        "equiv_error = equivariance_err_actor(agent,x, state_rep, action_rep, G)\n",
        "print(f\"Equivariance Error: {equiv_error:.2e}\")\n",
        "# equiv_error = equivariance_err_value(agent,x, state_rep, value_rep, G)\n",
        "# print(f\"Equivariance Error: {equiv_error:.2e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
