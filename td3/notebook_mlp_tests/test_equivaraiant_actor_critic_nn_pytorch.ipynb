{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qspqbJOVOpN-"
      },
      "source": [
        "## Equivaraint TD3 Actor and QNetwork Test (Pytorch Implementation)\n",
        "### Symmetrzier Package\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from symmetrizer.nn.modules import BasisLinear\n",
        "from symmetrizer.ops import GroupRepresentations\n",
        "from symmetrizer.groups import MatrixRepresentation\n",
        "import numpy as np\n",
        "\n",
        "class InvariantQNetwork(nn.Module):\n",
        "    def __init__(self, repr_in, repr_out, hidden_sizes=64):\n",
        "        super().__init__()\n",
        "        basis = \"equivariant\"\n",
        "        gain_type = \"xavier\"\n",
        "        # First hidden layer\n",
        "        self.layer1 = BasisLinear(1, hidden_sizes, repr_in, basis=basis, gain_type=gain_type)\n",
        "        self.layer2 = BasisLinear(hidden_sizes, hidden_sizes, repr_out, basis=basis, gain_type=gain_type)\n",
        "        self.output_layer = BasisLinear(hidden_sizes, 1, repr_out, basis=basis, gain_type=gain_type)\n",
        "\n",
        "    def forward(self, x, a):\n",
        "        x = x.unsqueeze(1)\n",
        "        a = a.unsqueeze(1)\n",
        "        x = torch.cat([x, a], 2)\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        q_values = self.output_layer(x)\n",
        "        return q_values\n",
        "class EquiActor(nn.Module):\n",
        "    def __init__(self, repr_in, repr_out,hidden_size):\n",
        "        super().__init__()\n",
        "        basis = \"equivariant\"\n",
        "        gain_type = \"xavier\"\n",
        "\n",
        "        self.fc1 = BasisLinear(1, hidden_size, group=repr_in, basis=basis, gain_type=gain_type, bias_init=False)\n",
        "        self.fc2 = BasisLinear(hidden_size, hidden_size, group=repr_out, basis=basis, gain_type=gain_type, bias_init=False)\n",
        "        self.fc_mu = BasisLinear(hidden_size, 1, group=repr_out, basis=basis, gain_type=gain_type, bias_init=False)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = torch.tanh(self.fc_mu(x))\n",
        "        x = x.squeeze(1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cpu\"\n",
        "ch = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "representations = [torch.FloatTensor(np.eye(4)), torch.FloatTensor(-1 * np.eye(4))]\n",
        "in_group = GroupRepresentations(representations, \"StateGroupRepr\")\n",
        "representations = [torch.FloatTensor(np.eye(1)), torch.FloatTensor(-1 * np.eye(1))]\n",
        "out_group = GroupRepresentations(representations, \"ActionGroupRepr\")\n",
        "\n",
        "repr_in = MatrixRepresentation(in_group, out_group)\n",
        "repr_out = MatrixRepresentation(out_group, out_group)\n",
        "actor = EquiActor(repr_in, repr_out, ch).to(device)\n",
        "\n",
        "\n",
        "representations = [torch.FloatTensor(np.eye(5)), torch.FloatTensor(-1 * np.eye(5))]\n",
        "in_group = GroupRepresentations(representations, \"StateGroupRepr\")\n",
        "representations = [torch.FloatTensor(np.eye(1)), torch.FloatTensor(-1 * np.eye(1))]\n",
        "out_group = GroupRepresentations(representations, \"ActionGroupRepr\")\n",
        "repr_in_q = MatrixRepresentation(in_group, out_group)\n",
        "representations = [torch.FloatTensor(np.eye(1)), torch.FloatTensor(np.eye(1))]\n",
        "out_group_q =  GroupRepresentations(representations, \"InvariantGroupRepr\")\n",
        "repr_out_q = MatrixRepresentation(out_group_q, out_group_q)\n",
        "\n",
        "qf = InvariantQNetwork( repr_in_q, repr_out_q, ch).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def actor_equivariance_mae(network, obs: torch.Tensor, repr_in: MatrixRepresentation, repr_out: MatrixRepresentation) -> float:\n",
        "    \"\"\"\n",
        "    Calculate the MSE of the equivariance error for the actor network.\n",
        "    \"\"\"\n",
        "    transformed_inputs = torch.stack([torch.matmul(obs, p_in) for p_in in repr_in._input_matrices])\n",
        "    y1 = torch.stack([network(p_x) for p_x in transformed_inputs])\n",
        "    y2 = torch.stack([torch.matmul(network(obs),p_out) for p_out in repr_out._output_matrices])\n",
        "    return (y1.abs() - y2.abs()).abs().mean().item()\n",
        "\n",
        "def q_equivariance_mae(network, obs: torch.Tensor, actions: torch.Tensor, repr_in_q: MatrixRepresentation) -> float:\n",
        "    \"\"\"\n",
        "    Calculate the MSE of the equivariance error for the Q-network.\n",
        "    \"\"\"\n",
        "    obs_actions = torch.cat([obs, actions], dim=-1)\n",
        "    transformed_inputs = torch.stack([torch.matmul(obs_actions, p_in) for p_in in repr_in_q._input_matrices])\n",
        "    y1 = torch.stack([network(p_obs_actions[:, :obs.size(-1)], p_obs_actions[:, obs.size(-1):]) for p_obs_actions in transformed_inputs])\n",
        "    y2 = network(obs, actions).unsqueeze(0).expand_as(y1)\n",
        "\n",
        "    return (y1.abs() - y2.abs()).abs().mean().item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Actor equivariance error: 1.86e-01\n",
            "Q-network equivariance error: 3.95e-01\n"
          ]
        }
      ],
      "source": [
        "obs = torch.randn(50, 4) \n",
        "a = torch.randn(50, 1)\n",
        "err_a = actor_equivariance_mae(actor, obs, repr_in, repr_out)\n",
        "print(f\"Actor equivariance error: {err_a:.2e}\")\n",
        "err_q = q_equivariance_mae(qf, obs, a, repr_in_q)\n",
        "print(f\"Q-network equivariance error: {err_q:.2e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
