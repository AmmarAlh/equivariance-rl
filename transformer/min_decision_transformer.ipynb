{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./\n",
      "Processing: InvertedPendulum-v4-medium.hdf5\n",
      "Number of samples collected: 999790\n",
      "Trajectory returns: mean = 211.77505493164062, std = 4.659221172332764, max = 225.0, min = 197.0\n",
      "Processed dataset saved to ./processed_data/InvertedPendulum-v4-medium.pkl\n",
      "Processing: InvertedPendulum-v4-stitched.hdf5\n",
      "Number of samples collected: 1999790\n",
      "Trajectory returns: mean = 349.5525207519531, std = 299.39093017578125, max = 1000.0, min = 197.0\n",
      "Processed dataset saved to ./processed_data/InvertedPendulum-v4-stitched.pkl\n",
      "Processing: offline_data.hdf5\n",
      "Number of samples collected: 10000\n",
      "Trajectory returns: mean = 6.060606002807617, std = 3.417595863342285, max = 26.0, min = 3.0\n",
      "Processed dataset saved to ./processed_data/offline_data.pkl\n",
      "Processing: InvertedPendulum-v4-stitched-3.hdf5\n",
      "Number of samples collected: 2009790\n",
      "Trajectory returns: mean = 272.6617736816406, std = 300.1198425292969, max = 1000.0, min = 3.0\n",
      "Processed dataset saved to ./processed_data/InvertedPendulum-v4-stitched-3.pkl\n",
      "Processing: InvertedPendulum-v4-stitched-2.hdf5\n",
      "Number of samples collected: 2499788\n",
      "Trajectory returns: mean = 28.371862411499023, std = 113.99412536621094, max = 1000.0, min = 3.0\n",
      "Processed dataset saved to ./processed_data/InvertedPendulum-v4-stitched-2.pkl\n",
      "Processing: InvertedPendulum-v4-expert.hdf5\n",
      "Number of samples collected: 1000000\n",
      "Trajectory returns: mean = 1000.0, std = 0.0, max = 1000.0, min = 1000.0\n",
      "Processed dataset saved to ./processed_data/InvertedPendulum-v4-expert.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import collections\n",
    "import pickle\n",
    "import h5py\n",
    "\n",
    "data_dir = \"./\"\n",
    "output_dir = \"./processed_data\"\n",
    "\n",
    "print(data_dir)\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if not file_name.endswith(\".hdf5\"):\n",
    "        continue\n",
    "\n",
    "    file_path = os.path.join(data_dir, file_name)\n",
    "    output_file_path = os.path.join(output_dir, f\"{os.path.splitext(file_name)[0]}.pkl\")\n",
    "\n",
    "    print(f\"Processing: {file_name}\")\n",
    "\n",
    "    # Load the dataset\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        dataset = {key: np.array(f[key]) for key in f.keys()}\n",
    "        # Metadata is not needed for processing trajectories\n",
    "        if 'metadata' in dataset:\n",
    "            del dataset['metadata']\n",
    "\n",
    "    # Determine the number of samples\n",
    "    N = dataset['rewards'].shape[0]\n",
    "    data_ = collections.defaultdict(list)\n",
    "\n",
    "    episode_step = 0\n",
    "    paths = []\n",
    "\n",
    "    for i in range(N):\n",
    "        # Extract terminal and timeout conditions\n",
    "        done_bool = bool(dataset['terminals'][i])\n",
    "        timeout = bool(dataset['timeouts'][i])\n",
    "\n",
    "        # Accumulate trajectory data\n",
    "        for k in ['observations', 'next_observations', 'actions', 'rewards', 'terminals']:\n",
    "            data_[k].append(dataset[k][i])\n",
    "\n",
    "        # Check if the trajectory has ended\n",
    "        if done_bool or timeout:\n",
    "            episode_step = 0\n",
    "            episode_data = {}\n",
    "            for k in data_:\n",
    "                episode_data[k] = np.array(data_[k])\n",
    "            paths.append(episode_data)\n",
    "            data_ = collections.defaultdict(list)\n",
    "        episode_step += 1\n",
    "\n",
    "    # Compute trajectory statistics\n",
    "    returns = np.array([np.sum(p['rewards']) for p in paths])\n",
    "    num_samples = np.sum([p['rewards'].shape[0] for p in paths])\n",
    "    print(f'Number of samples collected: {num_samples}')\n",
    "    print(f'Trajectory returns: mean = {np.mean(returns)}, std = {np.std(returns)}, max = {np.max(returns)}, min = {np.min(returns)}')\n",
    "\n",
    "    # Save trajectories to a pickle file\n",
    "    with open(output_file_path, 'wb') as f:\n",
    "        pickle.dump(paths, f)\n",
    "\n",
    "    print(f\"Processed dataset saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2Nk5Gp7hUGA"
   },
   "source": [
    "# import libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "q4xiijmBixUm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQcLNRgD6SaW"
   },
   "source": [
    "# training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "WdtDsvit6m_e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device set to:  cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = \"stitched\"       # medium / medium-replay / medium-expert\n",
    "rtg_scale = 1000                # scale to normalize returns to go\n",
    "\n",
    "\n",
    "env_name = 'InvertedPendulum-v4'\n",
    "rtg_target = 10000\n",
    "env_d4rl_name = f'InvertedPendulum-v4-{dataset}'\n",
    "\n",
    "\n",
    "max_eval_ep_len = 1000      # max len of one evaluation episode\n",
    "num_eval_ep = 10            # num of evaluation episodes per iteration\n",
    "\n",
    "batch_size = 64             # training batch size\n",
    "lr = 2e-4                   # learning rate\n",
    "wt_decay = 1e-4             # weight decay\n",
    "warmup_steps = 10000        # warmup steps for lr scheduler\n",
    "\n",
    "# total updates = max_train_iters x num_updates_per_iter\n",
    "max_train_iters = 200\n",
    "num_updates_per_iter = 1000\n",
    "\n",
    "context_len = 5        # K in decision transformer\n",
    "n_blocks = 3            # num of transformer blocks\n",
    "embed_dim = 128         # embedding (hidden) dim of transformer\n",
    "n_heads = 1             # num of transformer heads\n",
    "dropout_p = 0.1         # dropout probability\n",
    "\n",
    "\n",
    "\n",
    "# load data from this file\n",
    "dataset_path = f'processed_data/{env_d4rl_name}.pkl'\n",
    "\n",
    "# saves model and csv in this directory\n",
    "log_dir = \"./dt_runs/\"\n",
    "\n",
    "\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "\n",
    "# training and evaluation device\n",
    "device_name = 'cuda'\n",
    "device = torch.device(device_name)\n",
    "print(\"device set to: \", device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wNJM0LG1iziA"
   },
   "source": [
    "# decision transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "MHMl_Y1SicXb"
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "this extremely minimal GPT model is based on:\n",
    "Misha Laskin's tweet:\n",
    "https://twitter.com/MishaLaskin/status/1481767788775628801?cxt=HHwWgoCzmYD9pZApAAAA\n",
    "\n",
    "and its corresponding notebook:\n",
    "https://colab.research.google.com/drive/1NUBqyboDcGte5qAJKOl8gaJC28V_73Iv?usp=sharing\n",
    "\n",
    "the above colab has a bug while applying masked_fill which is fixed in the\n",
    "following code\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class MaskedCausalAttention(nn.Module):\n",
    "    def __init__(self, h_dim, max_T, n_heads, drop_p):\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "        self.max_T = max_T\n",
    "\n",
    "        self.q_net = nn.Linear(h_dim, h_dim)\n",
    "        self.k_net = nn.Linear(h_dim, h_dim)\n",
    "        self.v_net = nn.Linear(h_dim, h_dim)\n",
    "\n",
    "        self.proj_net = nn.Linear(h_dim, h_dim)\n",
    "\n",
    "        self.att_drop = nn.Dropout(drop_p)\n",
    "        self.proj_drop = nn.Dropout(drop_p)\n",
    "\n",
    "        ones = torch.ones((max_T, max_T))\n",
    "        mask = torch.tril(ones).view(1, 1, max_T, max_T)\n",
    "\n",
    "        # register buffer makes sure mask does not get updated\n",
    "        # during backpropagation\n",
    "        self.register_buffer('mask',mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape # batch size, seq length, h_dim * n_heads\n",
    "\n",
    "        N, D = self.n_heads, C // self.n_heads # N = num heads, D = attention dim\n",
    "\n",
    "        # rearrange q, k, v as (B, N, T, D)\n",
    "        q = self.q_net(x).view(B, T, N, D).transpose(1,2)\n",
    "        k = self.k_net(x).view(B, T, N, D).transpose(1,2)\n",
    "        v = self.v_net(x).view(B, T, N, D).transpose(1,2)\n",
    "\n",
    "        # weights (B, N, T, T)\n",
    "        weights = q @ k.transpose(2,3) / math.sqrt(D)\n",
    "        # causal mask applied to weights\n",
    "        weights = weights.masked_fill(self.mask[...,:T,:T] == 0, float('-inf'))\n",
    "        # normalize weights, all -inf -> 0 after softmax\n",
    "        normalized_weights = F.softmax(weights, dim=-1)\n",
    "\n",
    "        # attention (B, N, T, D)\n",
    "        attention = self.att_drop(normalized_weights @ v)\n",
    "\n",
    "        # gather heads and project (B, N, T, D) -> (B, T, N*D)\n",
    "        attention = attention.transpose(1, 2).contiguous().view(B,T,N*D)\n",
    "\n",
    "        out = self.proj_drop(self.proj_net(attention))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, h_dim, max_T, n_heads, drop_p):\n",
    "        super().__init__()\n",
    "        self.attention = MaskedCausalAttention(h_dim, max_T, n_heads, drop_p)\n",
    "        self.mlp = nn.Sequential(\n",
    "                nn.Linear(h_dim, 4*h_dim),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(4*h_dim, h_dim),\n",
    "                nn.Dropout(drop_p),\n",
    "            )\n",
    "        self.ln1 = nn.LayerNorm(h_dim)\n",
    "        self.ln2 = nn.LayerNorm(h_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Attention -> LayerNorm -> MLP -> LayerNorm\n",
    "        x = x + self.attention(x) # residual\n",
    "        x = self.ln1(x)\n",
    "        x = x + self.mlp(x) # residual\n",
    "        x = self.ln2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecisionTransformer(nn.Module):\n",
    "    def __init__(self, state_dim, act_dim, n_blocks, h_dim, context_len,\n",
    "                 n_heads, drop_p, max_timestep=4096):\n",
    "        super().__init__()\n",
    "\n",
    "        self.state_dim = state_dim\n",
    "        self.act_dim = act_dim\n",
    "        self.h_dim = h_dim\n",
    "\n",
    "        ### transformer blocks\n",
    "        input_seq_len = 3 * context_len\n",
    "        blocks = [Block(h_dim, input_seq_len, n_heads, drop_p) for _ in range(n_blocks)]\n",
    "        self.transformer = nn.Sequential(*blocks)\n",
    "\n",
    "        ### projection heads (project to embedding)\n",
    "        self.embed_ln = nn.LayerNorm(h_dim)\n",
    "        self.embed_timestep = nn.Embedding(max_timestep, h_dim)\n",
    "        self.embed_rtg = torch.nn.Linear(1, h_dim)\n",
    "        self.embed_state = torch.nn.Linear(state_dim, h_dim)\n",
    "\n",
    "        # # discrete actions\n",
    "        # self.embed_action = torch.nn.Embedding(act_dim, h_dim)\n",
    "        # use_action_tanh = False # False for discrete actions\n",
    "\n",
    "        # continuous actions\n",
    "        self.embed_action = torch.nn.Linear(act_dim, h_dim)\n",
    "        use_action_tanh = True # True for continuous actions\n",
    "\n",
    "        ### prediction heads\n",
    "        self.predict_rtg = torch.nn.Linear(h_dim, 1)\n",
    "        self.predict_state = torch.nn.Linear(h_dim, state_dim)\n",
    "        self.predict_action = nn.Sequential(\n",
    "            *([nn.Linear(h_dim, act_dim)] + ([nn.Tanh()] if use_action_tanh else []))\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, timesteps, states, actions, returns_to_go):\n",
    "\n",
    "        B, T, _ = states.shape\n",
    "\n",
    "        time_embeddings = self.embed_timestep(timesteps)\n",
    "\n",
    "        # time embeddings are treated similar to positional embeddings\n",
    "        state_embeddings = self.embed_state(states) + time_embeddings\n",
    "        action_embeddings = self.embed_action(actions) + time_embeddings\n",
    "        returns_embeddings = self.embed_rtg(returns_to_go) + time_embeddings\n",
    "\n",
    "        # stack rtg, states and actions and reshape sequence as\n",
    "        # (r1, s1, a1, r2, s2, a2 ...)\n",
    "        h = torch.stack(\n",
    "            (returns_embeddings, state_embeddings, action_embeddings), dim=1\n",
    "        ).permute(0, 2, 1, 3).reshape(B, 3 * T, self.h_dim)\n",
    "\n",
    "        h = self.embed_ln(h)\n",
    "\n",
    "        # transformer and prediction\n",
    "        h = self.transformer(h)\n",
    "\n",
    "        # get h reshaped such that its size = (B x 3 x T x h_dim) and\n",
    "        # h[:, 0, t] is conditioned on r_0, s_0, a_0 ... r_t\n",
    "        # h[:, 1, t] is conditioned on r_0, s_0, a_0 ... r_t, s_t\n",
    "        # h[:, 2, t] is conditioned on r_0, s_0, a_0 ... r_t, s_t, a_t\n",
    "        h = h.reshape(B, T, 3, self.h_dim).permute(0, 2, 1, 3)\n",
    "\n",
    "        # get predictions\n",
    "        return_preds = self.predict_rtg(h[:,2])     # predict next rtg given r, s, a\n",
    "        state_preds = self.predict_state(h[:,2])    # predict next state given r, s, a\n",
    "        action_preds = self.predict_action(h[:,1])  # predict action given r, s\n",
    "\n",
    "        return state_preds, action_preds, return_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pewE01Ca4BG0"
   },
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EaaymCHPlynF"
   },
   "outputs": [],
   "source": [
    "REF_MAX_SCORE = {\n",
    "    'halfcheetah' : 12135.0,\n",
    "    'walker2d' : 4592.3,\n",
    "    'hopper' : 3234.3,\n",
    "    'invertedpendulum' : 1000.0,\n",
    "}\n",
    "\n",
    "REF_MIN_SCORE = {\n",
    "    'halfcheetah' : -280.178953,\n",
    "    'walker2d' : 1.629008,\n",
    "    'hopper' : -20.272305,\n",
    "    'invertedpendulum' : 3.0,\n",
    "}\n",
    "\n",
    "def discount_cumsum(x, gamma):\n",
    "    disc_cumsum = np.zeros_like(x)\n",
    "    disc_cumsum[-1] = x[-1]\n",
    "    for t in reversed(range(x.shape[0]-1)):\n",
    "        disc_cumsum[t] = x[t] + gamma * disc_cumsum[t+1]\n",
    "    return disc_cumsum\n",
    "\n",
    "\n",
    "def get_d4rl_normalized_score(score, env_name):\n",
    "    env_key = env_name.split('-')[0].lower()\n",
    "    assert env_key in REF_MAX_SCORE, f'no reference score for {env_key} env to calculate d4rl score'\n",
    "    return (score - REF_MIN_SCORE[env_key]) / (REF_MAX_SCORE[env_key] - REF_MIN_SCORE[env_key])\n",
    "\n",
    "\n",
    "def evaluate_on_env(model, device, context_len, env, rtg_target, rtg_scale,\n",
    "                    num_eval_ep=10, max_test_ep_len=1000,\n",
    "                    state_mean=None, state_std=None, render=False):\n",
    "\n",
    "    eval_batch_size = 1  # required for forward pass\n",
    "\n",
    "    results = {}\n",
    "    total_reward = 0\n",
    "    total_timesteps = 0\n",
    "\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    act_dim = env.action_space.shape[0]\n",
    "\n",
    "    if state_mean is None:\n",
    "        state_mean = torch.zeros((state_dim,)).to(device)\n",
    "    else:\n",
    "        state_mean = torch.from_numpy(state_mean).to(device)\n",
    "\n",
    "    if state_std is None:\n",
    "        state_std = torch.ones((state_dim,)).to(device)\n",
    "    else:\n",
    "        state_std = torch.from_numpy(state_std).to(device)\n",
    "\n",
    "    # same as timesteps used for training the transformer\n",
    "    # also, crashes if device is passed to arange()\n",
    "    timesteps = torch.arange(start=0, end=max_test_ep_len, step=1)\n",
    "    timesteps = timesteps.repeat(eval_batch_size, 1).to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for _ in range(num_eval_ep):\n",
    "\n",
    "            # zeros place holders\n",
    "            actions = torch.zeros((eval_batch_size, max_test_ep_len, act_dim),\n",
    "                                dtype=torch.float32, device=device)\n",
    "\n",
    "            states = torch.zeros((eval_batch_size, max_test_ep_len, state_dim),\n",
    "                                dtype=torch.float32, device=device)\n",
    "\n",
    "            rewards_to_go = torch.zeros((eval_batch_size, max_test_ep_len, 1),\n",
    "                                dtype=torch.float32, device=device)\n",
    "\n",
    "            # init episode\n",
    "            running_state,_ = env.reset(seed=12)\n",
    "            running_reward = 0\n",
    "            running_rtg = rtg_target / rtg_scale\n",
    "\n",
    "            for t in range(max_test_ep_len):\n",
    "\n",
    "                total_timesteps += 1\n",
    "\n",
    "                # add state in placeholder and normalize\n",
    "                states[0, t] = torch.from_numpy(running_state).to(device)\n",
    "                states[0, t] = (states[0, t] - state_mean) / state_std\n",
    "\n",
    "                # calcualate running rtg and add in placeholder\n",
    "                running_rtg = running_rtg - (running_reward / rtg_scale)\n",
    "                rewards_to_go[0, t] = running_rtg\n",
    "\n",
    "                if t < context_len:\n",
    "                    _, act_preds, _ = model.forward(timesteps[:,:context_len],\n",
    "                                                states[:,:context_len],\n",
    "                                                actions[:,:context_len],\n",
    "                                                rewards_to_go[:,:context_len])\n",
    "                    act = act_preds[0, t].detach()\n",
    "                else:\n",
    "                    _, act_preds, _ = model.forward(timesteps[:,t-context_len+1:t+1],\n",
    "                                                states[:,t-context_len+1:t+1],\n",
    "                                                actions[:,t-context_len+1:t+1],\n",
    "                                                rewards_to_go[:,t-context_len+1:t+1])\n",
    "                    act = act_preds[0, -1].detach()\n",
    "\n",
    "\n",
    "                running_state, running_reward, done, truncations, infos  = env.step(act.cpu().numpy())\n",
    "\n",
    "                # add action in placeholder\n",
    "                actions[0, t] = act\n",
    "\n",
    "                total_reward += running_reward\n",
    "\n",
    "                if render:\n",
    "                    env.render()\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "    results['eval/avg_reward'] = total_reward / num_eval_ep\n",
    "    results['eval/avg_ep_len'] = total_timesteps / num_eval_ep\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXXrs_PjAHrN"
   },
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "n1Vb5rY_iiME"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed_data/InvertedPendulum-v4-stitched.pkl\n",
      "num of trajectories in dataset:  5721\n",
      "minimum trajectory length in dataset:  197\n",
      "state mean:  [0.0017522607231512666, -0.005709932651370764, -0.01926964335143566, -0.011516096070408821]\n",
      "state std:  [0.12814675271511078, 0.01897534169256687, 0.161709263920784, 0.3604785203933716]\n"
     ]
    }
   ],
   "source": [
    "## check data\n",
    "\n",
    "# load dataset\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    trajectories = pickle.load(f)\n",
    "\n",
    "min_len = 10**4\n",
    "states = []\n",
    "for traj in trajectories:\n",
    "    min_len = min(min_len, traj['observations'].shape[0])\n",
    "    states.append(traj['observations'])\n",
    "\n",
    "# used for input normalization\n",
    "states = np.concatenate(states, axis=0)\n",
    "state_mean, state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "\n",
    "print(dataset_path)\n",
    "print(\"num of trajectories in dataset: \", len(trajectories))\n",
    "print(\"minimum trajectory length in dataset: \", min_len)\n",
    "print(\"state mean: \", state_mean.tolist())\n",
    "print(\"state std: \", state_std.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "eo4zPTjjn0Qr"
   },
   "outputs": [],
   "source": [
    "\n",
    "class D4RLTrajectoryDataset(Dataset):\n",
    "    def __init__(self, dataset_path, context_len, rtg_scale):\n",
    "        self.context_len = context_len\n",
    "\n",
    "        # load dataset\n",
    "        with open(dataset_path, 'rb') as f:\n",
    "            self.trajectories = pickle.load(f)\n",
    "\n",
    "        # Handle Gymnasium `timeouts`\n",
    "        for traj in self.trajectories:\n",
    "            if 'timeouts' in traj:\n",
    "                traj['terminals'] = np.logical_or(traj['terminals'], traj['timeouts'])\n",
    "\n",
    "        # calculate min len of traj, state mean and variance\n",
    "        # and returns_to-go for all traj\n",
    "        min_len = 10**6\n",
    "        states = []\n",
    "        for traj in self.trajectories:\n",
    "            traj_len = traj['observations'].shape[0]\n",
    "            min_len = min(min_len, traj_len)\n",
    "            states.append(traj['observations'])\n",
    "            # calculate returns-to-go and rescale them\n",
    "            traj['returns_to_go'] = discount_cumsum(traj['rewards'], 1.0) / rtg_scale\n",
    "\n",
    "        # used for input normalization\n",
    "        states = np.concatenate(states, axis=0)\n",
    "        self.state_mean, self.state_std = np.mean(states, axis=0), np.std(states, axis=0) + 1e-6\n",
    "\n",
    "        # normalize states\n",
    "        for traj in self.trajectories:\n",
    "            traj['observations'] = (traj['observations'] - self.state_mean) / self.state_std\n",
    "\n",
    "    def get_state_stats(self):\n",
    "        return self.state_mean, self.state_std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.trajectories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        traj = self.trajectories[idx]\n",
    "        traj_len = traj['observations'].shape[0]\n",
    "\n",
    "        if traj_len >= self.context_len:\n",
    "            # sample random index to slice trajectory\n",
    "            si = random.randint(0, traj_len - self.context_len)\n",
    "\n",
    "            states = torch.from_numpy(traj['observations'][si : si + self.context_len])\n",
    "            actions = torch.from_numpy(traj['actions'][si : si + self.context_len])\n",
    "            returns_to_go = torch.from_numpy(traj['returns_to_go'][si : si + self.context_len])\n",
    "            timesteps = torch.arange(start=si, end=si+self.context_len, step=1)\n",
    "\n",
    "            # all ones since no padding\n",
    "            traj_mask = torch.ones(self.context_len, dtype=torch.long)\n",
    "\n",
    "        else:\n",
    "            padding_len = self.context_len - traj_len\n",
    "\n",
    "            # padding with zeros\n",
    "            states = torch.from_numpy(traj['observations'])\n",
    "            states = torch.cat([states,\n",
    "                                torch.zeros(([padding_len] + list(states.shape[1:])),\n",
    "                                dtype=states.dtype)],\n",
    "                               dim=0)\n",
    "\n",
    "            actions = torch.from_numpy(traj['actions'])\n",
    "            actions = torch.cat([actions,\n",
    "                                torch.zeros(([padding_len] + list(actions.shape[1:])),\n",
    "                                dtype=actions.dtype)],\n",
    "                               dim=0)\n",
    "\n",
    "            returns_to_go = torch.from_numpy(traj['returns_to_go'])\n",
    "            returns_to_go = torch.cat([returns_to_go,\n",
    "                                torch.zeros(([padding_len] + list(returns_to_go.shape[1:])),\n",
    "                                dtype=returns_to_go.dtype)],\n",
    "                               dim=0)\n",
    "\n",
    "            timesteps = torch.arange(start=0, end=self.context_len, step=1)\n",
    "\n",
    "            traj_mask = torch.cat([torch.ones(traj_len, dtype=torch.long),\n",
    "                                   torch.zeros(padding_len, dtype=torch.long)],\n",
    "                                  dim=0)\n",
    "\n",
    "        return  timesteps, states, actions, returns_to_go, traj_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7AK6T9Picu-"
   },
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "RBLRM5nOVR_8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "start time: 24-11-23-09-03-41\n",
      "============================================================\n",
      "device set to: cuda\n",
      "dataset path: processed_data/InvertedPendulum-v4-stitched.pkl\n",
      "model save path: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "log csv save path: ./dt_runs/dt_InvertedPendulum-v4-stitched_log_24-11-23-09-03-41.csv\n",
      "============================================================\n",
      "time elapsed: 0:00:19\n",
      "num of updates: 1000\n",
      "action loss: 0.20848\n",
      "eval avg reward: 49.00000\n",
      "eval avg ep len: 49.00000\n",
      "eval d4rl score: 4.61384\n",
      "max d4rl score: -1.00000\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:36\n",
      "num of updates: 2000\n",
      "action loss: 0.08502\n",
      "eval avg reward: 57.00000\n",
      "eval avg ep len: 57.00000\n",
      "eval d4rl score: 5.41625\n",
      "max d4rl score: 4.61384\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:00:53\n",
      "num of updates: 3000\n",
      "action loss: 0.07218\n",
      "eval avg reward: 62.00000\n",
      "eval avg ep len: 62.00000\n",
      "eval d4rl score: 5.91775\n",
      "max d4rl score: 5.41625\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:11\n",
      "num of updates: 4000\n",
      "action loss: 0.06452\n",
      "eval avg reward: 65.00000\n",
      "eval avg ep len: 65.00000\n",
      "eval d4rl score: 6.21866\n",
      "max d4rl score: 5.91775\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:29\n",
      "num of updates: 5000\n",
      "action loss: 0.06012\n",
      "eval avg reward: 54.00000\n",
      "eval avg ep len: 54.00000\n",
      "eval d4rl score: 5.11535\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:01:47\n",
      "num of updates: 6000\n",
      "action loss: 0.05948\n",
      "eval avg reward: 58.00000\n",
      "eval avg ep len: 58.00000\n",
      "eval d4rl score: 5.51655\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:03\n",
      "num of updates: 7000\n",
      "action loss: 0.05871\n",
      "eval avg reward: 46.00000\n",
      "eval avg ep len: 46.00000\n",
      "eval d4rl score: 4.31294\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:20\n",
      "num of updates: 8000\n",
      "action loss: 0.05775\n",
      "eval avg reward: 54.00000\n",
      "eval avg ep len: 54.00000\n",
      "eval d4rl score: 5.11535\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:37\n",
      "num of updates: 9000\n",
      "action loss: 0.05858\n",
      "eval avg reward: 57.00000\n",
      "eval avg ep len: 57.00000\n",
      "eval d4rl score: 5.41625\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:02:54\n",
      "num of updates: 10000\n",
      "action loss: 0.05777\n",
      "eval avg reward: 49.00000\n",
      "eval avg ep len: 49.00000\n",
      "eval d4rl score: 4.61384\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:11\n",
      "num of updates: 11000\n",
      "action loss: 0.05896\n",
      "eval avg reward: 55.00000\n",
      "eval avg ep len: 55.00000\n",
      "eval d4rl score: 5.21565\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:28\n",
      "num of updates: 12000\n",
      "action loss: 0.05660\n",
      "eval avg reward: 54.00000\n",
      "eval avg ep len: 54.00000\n",
      "eval d4rl score: 5.11535\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:03:45\n",
      "num of updates: 13000\n",
      "action loss: 0.05652\n",
      "eval avg reward: 60.00000\n",
      "eval avg ep len: 60.00000\n",
      "eval d4rl score: 5.71715\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:02\n",
      "num of updates: 14000\n",
      "action loss: 0.05484\n",
      "eval avg reward: 56.00000\n",
      "eval avg ep len: 56.00000\n",
      "eval d4rl score: 5.31595\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:18\n",
      "num of updates: 15000\n",
      "action loss: 0.05384\n",
      "eval avg reward: 50.00000\n",
      "eval avg ep len: 50.00000\n",
      "eval d4rl score: 4.71414\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:35\n",
      "num of updates: 16000\n",
      "action loss: 0.05474\n",
      "eval avg reward: 53.00000\n",
      "eval avg ep len: 53.00000\n",
      "eval d4rl score: 5.01505\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:04:52\n",
      "num of updates: 17000\n",
      "action loss: 0.05483\n",
      "eval avg reward: 49.00000\n",
      "eval avg ep len: 49.00000\n",
      "eval d4rl score: 4.61384\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:09\n",
      "num of updates: 18000\n",
      "action loss: 0.05514\n",
      "eval avg reward: 44.00000\n",
      "eval avg ep len: 44.00000\n",
      "eval d4rl score: 4.11234\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:26\n",
      "num of updates: 19000\n",
      "action loss: 0.05412\n",
      "eval avg reward: 52.00000\n",
      "eval avg ep len: 52.00000\n",
      "eval d4rl score: 4.91474\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:43\n",
      "num of updates: 20000\n",
      "action loss: 0.05506\n",
      "eval avg reward: 57.00000\n",
      "eval avg ep len: 57.00000\n",
      "eval d4rl score: 5.41625\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:05:59\n",
      "num of updates: 21000\n",
      "action loss: 0.05535\n",
      "eval avg reward: 48.00000\n",
      "eval avg ep len: 48.00000\n",
      "eval d4rl score: 4.51354\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:16\n",
      "num of updates: 22000\n",
      "action loss: 0.05519\n",
      "eval avg reward: 45.00000\n",
      "eval avg ep len: 45.00000\n",
      "eval d4rl score: 4.21264\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:33\n",
      "num of updates: 23000\n",
      "action loss: 0.05455\n",
      "eval avg reward: 48.00000\n",
      "eval avg ep len: 48.00000\n",
      "eval d4rl score: 4.51354\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:06:49\n",
      "num of updates: 24000\n",
      "action loss: 0.05319\n",
      "eval avg reward: 46.00000\n",
      "eval avg ep len: 46.00000\n",
      "eval d4rl score: 4.31294\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:07:06\n",
      "num of updates: 25000\n",
      "action loss: 0.05398\n",
      "eval avg reward: 42.00000\n",
      "eval avg ep len: 42.00000\n",
      "eval d4rl score: 3.91174\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:07:24\n",
      "num of updates: 26000\n",
      "action loss: 0.05477\n",
      "eval avg reward: 51.00000\n",
      "eval avg ep len: 51.00000\n",
      "eval d4rl score: 4.81444\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:07:41\n",
      "num of updates: 27000\n",
      "action loss: 0.05403\n",
      "eval avg reward: 55.00000\n",
      "eval avg ep len: 55.00000\n",
      "eval d4rl score: 5.21565\n",
      "max d4rl score: 6.21866\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:07:59\n",
      "num of updates: 28000\n",
      "action loss: 0.05430\n",
      "eval avg reward: 66.00000\n",
      "eval avg ep len: 66.00000\n",
      "eval d4rl score: 6.31896\n",
      "max d4rl score: 6.21866\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:08:17\n",
      "num of updates: 29000\n",
      "action loss: 0.05561\n",
      "eval avg reward: 53.00000\n",
      "eval avg ep len: 53.00000\n",
      "eval d4rl score: 5.01505\n",
      "max d4rl score: 6.31896\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:08:33\n",
      "num of updates: 30000\n",
      "action loss: 0.05431\n",
      "eval avg reward: 49.00000\n",
      "eval avg ep len: 49.00000\n",
      "eval d4rl score: 4.61384\n",
      "max d4rl score: 6.31896\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:08:50\n",
      "num of updates: 31000\n",
      "action loss: 0.05386\n",
      "eval avg reward: 46.00000\n",
      "eval avg ep len: 46.00000\n",
      "eval d4rl score: 4.31294\n",
      "max d4rl score: 6.31896\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:09:07\n",
      "num of updates: 32000\n",
      "action loss: 0.05470\n",
      "eval avg reward: 48.00000\n",
      "eval avg ep len: 48.00000\n",
      "eval d4rl score: 4.51354\n",
      "max d4rl score: 6.31896\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:09:24\n",
      "num of updates: 33000\n",
      "action loss: 0.05430\n",
      "eval avg reward: 55.00000\n",
      "eval avg ep len: 55.00000\n",
      "eval d4rl score: 5.21565\n",
      "max d4rl score: 6.31896\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:09:41\n",
      "num of updates: 34000\n",
      "action loss: 0.05484\n",
      "eval avg reward: 57.00000\n",
      "eval avg ep len: 57.00000\n",
      "eval d4rl score: 5.41625\n",
      "max d4rl score: 6.31896\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:10:01\n",
      "num of updates: 35000\n",
      "action loss: 0.05383\n",
      "eval avg reward: 136.00000\n",
      "eval avg ep len: 136.00000\n",
      "eval d4rl score: 13.34002\n",
      "max d4rl score: 6.31896\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:10:19\n",
      "num of updates: 36000\n",
      "action loss: 0.05493\n",
      "eval avg reward: 78.00000\n",
      "eval avg ep len: 78.00000\n",
      "eval d4rl score: 7.52257\n",
      "max d4rl score: 13.34002\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:10:41\n",
      "num of updates: 37000\n",
      "action loss: 0.05484\n",
      "eval avg reward: 219.00000\n",
      "eval avg ep len: 219.00000\n",
      "eval d4rl score: 21.66499\n",
      "max d4rl score: 13.34002\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:10:58\n",
      "num of updates: 38000\n",
      "action loss: 0.05337\n",
      "eval avg reward: 48.00000\n",
      "eval avg ep len: 48.00000\n",
      "eval d4rl score: 4.51354\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:11:15\n",
      "num of updates: 39000\n",
      "action loss: 0.05469\n",
      "eval avg reward: 58.00000\n",
      "eval avg ep len: 58.00000\n",
      "eval d4rl score: 5.51655\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:11:33\n",
      "num of updates: 40000\n",
      "action loss: 0.05277\n",
      "eval avg reward: 85.00000\n",
      "eval avg ep len: 85.00000\n",
      "eval d4rl score: 8.22467\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:11:50\n",
      "num of updates: 41000\n",
      "action loss: 0.05472\n",
      "eval avg reward: 58.00000\n",
      "eval avg ep len: 58.00000\n",
      "eval d4rl score: 5.51655\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:12:09\n",
      "num of updates: 42000\n",
      "action loss: 0.05581\n",
      "eval avg reward: 82.00000\n",
      "eval avg ep len: 82.00000\n",
      "eval d4rl score: 7.92377\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:12:25\n",
      "num of updates: 43000\n",
      "action loss: 0.05513\n",
      "eval avg reward: 51.00000\n",
      "eval avg ep len: 51.00000\n",
      "eval d4rl score: 4.81444\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:12:42\n",
      "num of updates: 44000\n",
      "action loss: 0.05405\n",
      "eval avg reward: 49.00000\n",
      "eval avg ep len: 49.00000\n",
      "eval d4rl score: 4.61384\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:13:00\n",
      "num of updates: 45000\n",
      "action loss: 0.05462\n",
      "eval avg reward: 60.00000\n",
      "eval avg ep len: 60.00000\n",
      "eval d4rl score: 5.71715\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:13:17\n",
      "num of updates: 46000\n",
      "action loss: 0.05434\n",
      "eval avg reward: 50.00000\n",
      "eval avg ep len: 50.00000\n",
      "eval d4rl score: 4.71414\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:13:36\n",
      "num of updates: 47000\n",
      "action loss: 0.05540\n",
      "eval avg reward: 92.00000\n",
      "eval avg ep len: 92.00000\n",
      "eval d4rl score: 8.92678\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:13:53\n",
      "num of updates: 48000\n",
      "action loss: 0.05414\n",
      "eval avg reward: 49.00000\n",
      "eval avg ep len: 49.00000\n",
      "eval d4rl score: 4.61384\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:14:11\n",
      "num of updates: 49000\n",
      "action loss: 0.05360\n",
      "eval avg reward: 59.00000\n",
      "eval avg ep len: 59.00000\n",
      "eval d4rl score: 5.61685\n",
      "max d4rl score: 21.66499\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:14:35\n",
      "num of updates: 50000\n",
      "action loss: 0.05418\n",
      "eval avg reward: 241.00000\n",
      "eval avg ep len: 241.00000\n",
      "eval d4rl score: 23.87161\n",
      "max d4rl score: 21.66499\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:15:02\n",
      "num of updates: 51000\n",
      "action loss: 0.05393\n",
      "eval avg reward: 312.00000\n",
      "eval avg ep len: 312.00000\n",
      "eval d4rl score: 30.99298\n",
      "max d4rl score: 23.87161\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:15:26\n",
      "num of updates: 52000\n",
      "action loss: 0.05395\n",
      "eval avg reward: 273.00000\n",
      "eval avg ep len: 273.00000\n",
      "eval d4rl score: 27.08124\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:15:45\n",
      "num of updates: 53000\n",
      "action loss: 0.05336\n",
      "eval avg reward: 93.00000\n",
      "eval avg ep len: 93.00000\n",
      "eval d4rl score: 9.02708\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:16:03\n",
      "num of updates: 54000\n",
      "action loss: 0.05408\n",
      "eval avg reward: 85.00000\n",
      "eval avg ep len: 85.00000\n",
      "eval d4rl score: 8.22467\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:16:26\n",
      "num of updates: 55000\n",
      "action loss: 0.05483\n",
      "eval avg reward: 235.00000\n",
      "eval avg ep len: 235.00000\n",
      "eval d4rl score: 23.26981\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:16:51\n",
      "num of updates: 56000\n",
      "action loss: 0.05365\n",
      "eval avg reward: 271.00000\n",
      "eval avg ep len: 271.00000\n",
      "eval d4rl score: 26.88064\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:17:10\n",
      "num of updates: 57000\n",
      "action loss: 0.05349\n",
      "eval avg reward: 113.00000\n",
      "eval avg ep len: 113.00000\n",
      "eval d4rl score: 11.03310\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:17:27\n",
      "num of updates: 58000\n",
      "action loss: 0.05428\n",
      "eval avg reward: 53.00000\n",
      "eval avg ep len: 53.00000\n",
      "eval d4rl score: 5.01505\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:17:45\n",
      "num of updates: 59000\n",
      "action loss: 0.05466\n",
      "eval avg reward: 88.00000\n",
      "eval avg ep len: 88.00000\n",
      "eval d4rl score: 8.52558\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:18:03\n",
      "num of updates: 60000\n",
      "action loss: 0.05582\n",
      "eval avg reward: 77.00000\n",
      "eval avg ep len: 77.00000\n",
      "eval d4rl score: 7.42227\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:18:21\n",
      "num of updates: 61000\n",
      "action loss: 0.05316\n",
      "eval avg reward: 98.00000\n",
      "eval avg ep len: 98.00000\n",
      "eval d4rl score: 9.52859\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:18:44\n",
      "num of updates: 62000\n",
      "action loss: 0.05323\n",
      "eval avg reward: 235.00000\n",
      "eval avg ep len: 235.00000\n",
      "eval d4rl score: 23.26981\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:19:02\n",
      "num of updates: 63000\n",
      "action loss: 0.05322\n",
      "eval avg reward: 94.00000\n",
      "eval avg ep len: 94.00000\n",
      "eval d4rl score: 9.12738\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:19:26\n",
      "num of updates: 64000\n",
      "action loss: 0.05406\n",
      "eval avg reward: 235.00000\n",
      "eval avg ep len: 235.00000\n",
      "eval d4rl score: 23.26981\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:19:50\n",
      "num of updates: 65000\n",
      "action loss: 0.05345\n",
      "eval avg reward: 252.00000\n",
      "eval avg ep len: 252.00000\n",
      "eval d4rl score: 24.97492\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:20:12\n",
      "num of updates: 66000\n",
      "action loss: 0.05259\n",
      "eval avg reward: 236.00000\n",
      "eval avg ep len: 236.00000\n",
      "eval d4rl score: 23.37011\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:20:29\n",
      "num of updates: 67000\n",
      "action loss: 0.05373\n",
      "eval avg reward: 58.00000\n",
      "eval avg ep len: 58.00000\n",
      "eval d4rl score: 5.51655\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:20:51\n",
      "num of updates: 68000\n",
      "action loss: 0.05552\n",
      "eval avg reward: 194.00000\n",
      "eval avg ep len: 194.00000\n",
      "eval d4rl score: 19.15747\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:21:09\n",
      "num of updates: 69000\n",
      "action loss: 0.05547\n",
      "eval avg reward: 99.00000\n",
      "eval avg ep len: 99.00000\n",
      "eval d4rl score: 9.62889\n",
      "max d4rl score: 30.99298\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:21:36\n",
      "num of updates: 70000\n",
      "action loss: 0.05532\n",
      "eval avg reward: 348.00000\n",
      "eval avg ep len: 348.00000\n",
      "eval d4rl score: 34.60381\n",
      "max d4rl score: 30.99298\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:21:54\n",
      "num of updates: 71000\n",
      "action loss: 0.05676\n",
      "eval avg reward: 95.00000\n",
      "eval avg ep len: 95.00000\n",
      "eval d4rl score: 9.22768\n",
      "max d4rl score: 34.60381\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:22:12\n",
      "num of updates: 72000\n",
      "action loss: 0.05413\n",
      "eval avg reward: 92.00000\n",
      "eval avg ep len: 92.00000\n",
      "eval d4rl score: 8.92678\n",
      "max d4rl score: 34.60381\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:22:32\n",
      "num of updates: 73000\n",
      "action loss: 0.05390\n",
      "eval avg reward: 148.00000\n",
      "eval avg ep len: 148.00000\n",
      "eval d4rl score: 14.54363\n",
      "max d4rl score: 34.60381\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:22:55\n",
      "num of updates: 74000\n",
      "action loss: 0.05502\n",
      "eval avg reward: 252.00000\n",
      "eval avg ep len: 252.00000\n",
      "eval d4rl score: 24.97492\n",
      "max d4rl score: 34.60381\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:23:14\n",
      "num of updates: 75000\n",
      "action loss: 0.05389\n",
      "eval avg reward: 123.00000\n",
      "eval avg ep len: 123.00000\n",
      "eval d4rl score: 12.03611\n",
      "max d4rl score: 34.60381\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:23:34\n",
      "num of updates: 76000\n",
      "action loss: 0.05475\n",
      "eval avg reward: 137.00000\n",
      "eval avg ep len: 137.00000\n",
      "eval d4rl score: 13.44032\n",
      "max d4rl score: 34.60381\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:23:59\n",
      "num of updates: 77000\n",
      "action loss: 0.05387\n",
      "eval avg reward: 294.00000\n",
      "eval avg ep len: 294.00000\n",
      "eval d4rl score: 29.18756\n",
      "max d4rl score: 34.60381\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:24:23\n",
      "num of updates: 78000\n",
      "action loss: 0.05440\n",
      "eval avg reward: 267.00000\n",
      "eval avg ep len: 267.00000\n",
      "eval d4rl score: 26.47944\n",
      "max d4rl score: 34.60381\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:24:41\n",
      "num of updates: 79000\n",
      "action loss: 0.05474\n",
      "eval avg reward: 100.00000\n",
      "eval avg ep len: 100.00000\n",
      "eval d4rl score: 9.72919\n",
      "max d4rl score: 34.60381\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:25:11\n",
      "num of updates: 80000\n",
      "action loss: 0.05440\n",
      "eval avg reward: 435.00000\n",
      "eval avg ep len: 435.00000\n",
      "eval d4rl score: 43.32999\n",
      "max d4rl score: 34.60381\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:25:39\n",
      "num of updates: 81000\n",
      "action loss: 0.05316\n",
      "eval avg reward: 355.00000\n",
      "eval avg ep len: 355.00000\n",
      "eval d4rl score: 35.30592\n",
      "max d4rl score: 43.32999\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:26:08\n",
      "num of updates: 82000\n",
      "action loss: 0.05488\n",
      "eval avg reward: 429.00000\n",
      "eval avg ep len: 429.00000\n",
      "eval d4rl score: 42.72818\n",
      "max d4rl score: 43.32999\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:26:28\n",
      "num of updates: 83000\n",
      "action loss: 0.05339\n",
      "eval avg reward: 140.00000\n",
      "eval avg ep len: 140.00000\n",
      "eval d4rl score: 13.74122\n",
      "max d4rl score: 43.32999\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:26:54\n",
      "num of updates: 84000\n",
      "action loss: 0.05507\n",
      "eval avg reward: 325.00000\n",
      "eval avg ep len: 325.00000\n",
      "eval d4rl score: 32.29689\n",
      "max d4rl score: 43.32999\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:27:26\n",
      "num of updates: 85000\n",
      "action loss: 0.05274\n",
      "eval avg reward: 498.00000\n",
      "eval avg ep len: 498.00000\n",
      "eval d4rl score: 49.64895\n",
      "max d4rl score: 43.32999\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:27:52\n",
      "num of updates: 86000\n",
      "action loss: 0.05306\n",
      "eval avg reward: 343.00000\n",
      "eval avg ep len: 343.00000\n",
      "eval d4rl score: 34.10231\n",
      "max d4rl score: 49.64895\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:28:11\n",
      "num of updates: 87000\n",
      "action loss: 0.05375\n",
      "eval avg reward: 101.00000\n",
      "eval avg ep len: 101.00000\n",
      "eval d4rl score: 9.82949\n",
      "max d4rl score: 49.64895\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:28:41\n",
      "num of updates: 88000\n",
      "action loss: 0.05345\n",
      "eval avg reward: 466.00000\n",
      "eval avg ep len: 466.00000\n",
      "eval d4rl score: 46.43932\n",
      "max d4rl score: 49.64895\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:29:14\n",
      "num of updates: 89000\n",
      "action loss: 0.05416\n",
      "eval avg reward: 568.00000\n",
      "eval avg ep len: 568.00000\n",
      "eval d4rl score: 56.67001\n",
      "max d4rl score: 49.64895\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:29:50\n",
      "num of updates: 90000\n",
      "action loss: 0.05235\n",
      "eval avg reward: 655.00000\n",
      "eval avg ep len: 655.00000\n",
      "eval d4rl score: 65.39619\n",
      "max d4rl score: 56.67001\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:30:08\n",
      "num of updates: 91000\n",
      "action loss: 0.05418\n",
      "eval avg reward: 102.00000\n",
      "eval avg ep len: 102.00000\n",
      "eval d4rl score: 9.92979\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:30:39\n",
      "num of updates: 92000\n",
      "action loss: 0.05352\n",
      "eval avg reward: 481.00000\n",
      "eval avg ep len: 481.00000\n",
      "eval d4rl score: 47.94383\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:30:58\n",
      "num of updates: 93000\n",
      "action loss: 0.05342\n",
      "eval avg reward: 123.00000\n",
      "eval avg ep len: 123.00000\n",
      "eval d4rl score: 12.03611\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:31:19\n",
      "num of updates: 94000\n",
      "action loss: 0.05289\n",
      "eval avg reward: 141.00000\n",
      "eval avg ep len: 141.00000\n",
      "eval d4rl score: 13.84152\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:31:48\n",
      "num of updates: 95000\n",
      "action loss: 0.05387\n",
      "eval avg reward: 418.00000\n",
      "eval avg ep len: 418.00000\n",
      "eval d4rl score: 41.62487\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:32:19\n",
      "num of updates: 96000\n",
      "action loss: 0.05453\n",
      "eval avg reward: 465.00000\n",
      "eval avg ep len: 465.00000\n",
      "eval d4rl score: 46.33902\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:32:48\n",
      "num of updates: 97000\n",
      "action loss: 0.05439\n",
      "eval avg reward: 441.00000\n",
      "eval avg ep len: 441.00000\n",
      "eval d4rl score: 43.93180\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:33:12\n",
      "num of updates: 98000\n",
      "action loss: 0.05328\n",
      "eval avg reward: 265.00000\n",
      "eval avg ep len: 265.00000\n",
      "eval d4rl score: 26.27884\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:33:39\n",
      "num of updates: 99000\n",
      "action loss: 0.05376\n",
      "eval avg reward: 344.00000\n",
      "eval avg ep len: 344.00000\n",
      "eval d4rl score: 34.20261\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:34:03\n",
      "num of updates: 100000\n",
      "action loss: 0.05354\n",
      "eval avg reward: 271.00000\n",
      "eval avg ep len: 271.00000\n",
      "eval d4rl score: 26.88064\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:34:37\n",
      "num of updates: 101000\n",
      "action loss: 0.05404\n",
      "eval avg reward: 585.00000\n",
      "eval avg ep len: 585.00000\n",
      "eval d4rl score: 58.37513\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:35:08\n",
      "num of updates: 102000\n",
      "action loss: 0.05525\n",
      "eval avg reward: 501.00000\n",
      "eval avg ep len: 501.00000\n",
      "eval d4rl score: 49.94985\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:35:43\n",
      "num of updates: 103000\n",
      "action loss: 0.05457\n",
      "eval avg reward: 606.00000\n",
      "eval avg ep len: 606.00000\n",
      "eval d4rl score: 60.48144\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:36:16\n",
      "num of updates: 104000\n",
      "action loss: 0.05419\n",
      "eval avg reward: 533.00000\n",
      "eval avg ep len: 533.00000\n",
      "eval d4rl score: 53.15948\n",
      "max d4rl score: 65.39619\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:37:05\n",
      "num of updates: 105000\n",
      "action loss: 0.05479\n",
      "eval avg reward: 1000.00000\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 100.00000\n",
      "max d4rl score: 65.39619\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:37:40\n",
      "num of updates: 106000\n",
      "action loss: 0.05417\n",
      "eval avg reward: 577.00000\n",
      "eval avg ep len: 577.00000\n",
      "eval d4rl score: 57.57272\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:38:11\n",
      "num of updates: 107000\n",
      "action loss: 0.05487\n",
      "eval avg reward: 476.00000\n",
      "eval avg ep len: 476.00000\n",
      "eval d4rl score: 47.44233\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:38:46\n",
      "num of updates: 108000\n",
      "action loss: 0.05485\n",
      "eval avg reward: 623.00000\n",
      "eval avg ep len: 623.00000\n",
      "eval d4rl score: 62.18656\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:39:21\n",
      "num of updates: 109000\n",
      "action loss: 0.05422\n",
      "eval avg reward: 641.00000\n",
      "eval avg ep len: 641.00000\n",
      "eval d4rl score: 63.99198\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:39:55\n",
      "num of updates: 110000\n",
      "action loss: 0.05378\n",
      "eval avg reward: 600.00000\n",
      "eval avg ep len: 600.00000\n",
      "eval d4rl score: 59.87964\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:40:28\n",
      "num of updates: 111000\n",
      "action loss: 0.05398\n",
      "eval avg reward: 598.00000\n",
      "eval avg ep len: 598.00000\n",
      "eval d4rl score: 59.67904\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:41:01\n",
      "num of updates: 112000\n",
      "action loss: 0.05517\n",
      "eval avg reward: 564.00000\n",
      "eval avg ep len: 564.00000\n",
      "eval d4rl score: 56.26881\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:41:34\n",
      "num of updates: 113000\n",
      "action loss: 0.05499\n",
      "eval avg reward: 567.00000\n",
      "eval avg ep len: 567.00000\n",
      "eval d4rl score: 56.56971\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:42:09\n",
      "num of updates: 114000\n",
      "action loss: 0.05416\n",
      "eval avg reward: 640.00000\n",
      "eval avg ep len: 640.00000\n",
      "eval d4rl score: 63.89168\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:42:39\n",
      "num of updates: 115000\n",
      "action loss: 0.05305\n",
      "eval avg reward: 441.00000\n",
      "eval avg ep len: 441.00000\n",
      "eval d4rl score: 43.93180\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:43:14\n",
      "num of updates: 116000\n",
      "action loss: 0.05391\n",
      "eval avg reward: 575.00000\n",
      "eval avg ep len: 575.00000\n",
      "eval d4rl score: 57.37212\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:43:49\n",
      "num of updates: 117000\n",
      "action loss: 0.05416\n",
      "eval avg reward: 607.00000\n",
      "eval avg ep len: 607.00000\n",
      "eval d4rl score: 60.58175\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:44:24\n",
      "num of updates: 118000\n",
      "action loss: 0.05406\n",
      "eval avg reward: 617.00000\n",
      "eval avg ep len: 617.00000\n",
      "eval d4rl score: 61.58475\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:45:11\n",
      "num of updates: 119000\n",
      "action loss: 0.05554\n",
      "eval avg reward: 1000.00000\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 100.00000\n",
      "max d4rl score: 100.00000\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:45:42\n",
      "num of updates: 120000\n",
      "action loss: 0.05414\n",
      "eval avg reward: 487.00000\n",
      "eval avg ep len: 487.00000\n",
      "eval d4rl score: 48.54564\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:46:17\n",
      "num of updates: 121000\n",
      "action loss: 0.05461\n",
      "eval avg reward: 589.00000\n",
      "eval avg ep len: 589.00000\n",
      "eval d4rl score: 58.77633\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:46:54\n",
      "num of updates: 122000\n",
      "action loss: 0.05453\n",
      "eval avg reward: 596.00000\n",
      "eval avg ep len: 596.00000\n",
      "eval d4rl score: 59.47844\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:47:29\n",
      "num of updates: 123000\n",
      "action loss: 0.05419\n",
      "eval avg reward: 615.00000\n",
      "eval avg ep len: 615.00000\n",
      "eval d4rl score: 61.38415\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:48:00\n",
      "num of updates: 124000\n",
      "action loss: 0.05493\n",
      "eval avg reward: 486.00000\n",
      "eval avg ep len: 486.00000\n",
      "eval d4rl score: 48.44534\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:48:31\n",
      "num of updates: 125000\n",
      "action loss: 0.05401\n",
      "eval avg reward: 514.00000\n",
      "eval avg ep len: 514.00000\n",
      "eval d4rl score: 51.25376\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:49:04\n",
      "num of updates: 126000\n",
      "action loss: 0.05481\n",
      "eval avg reward: 522.00000\n",
      "eval avg ep len: 522.00000\n",
      "eval d4rl score: 52.05617\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:49:25\n",
      "num of updates: 127000\n",
      "action loss: 0.05454\n",
      "eval avg reward: 165.00000\n",
      "eval avg ep len: 165.00000\n",
      "eval d4rl score: 16.24875\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:49:59\n",
      "num of updates: 128000\n",
      "action loss: 0.05541\n",
      "eval avg reward: 608.00000\n",
      "eval avg ep len: 608.00000\n",
      "eval d4rl score: 60.68205\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:50:33\n",
      "num of updates: 129000\n",
      "action loss: 0.05378\n",
      "eval avg reward: 584.00000\n",
      "eval avg ep len: 584.00000\n",
      "eval d4rl score: 58.27482\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:51:08\n",
      "num of updates: 130000\n",
      "action loss: 0.05440\n",
      "eval avg reward: 623.00000\n",
      "eval avg ep len: 623.00000\n",
      "eval d4rl score: 62.18656\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:51:41\n",
      "num of updates: 131000\n",
      "action loss: 0.05266\n",
      "eval avg reward: 561.00000\n",
      "eval avg ep len: 561.00000\n",
      "eval d4rl score: 55.96790\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:52:16\n",
      "num of updates: 132000\n",
      "action loss: 0.05406\n",
      "eval avg reward: 600.00000\n",
      "eval avg ep len: 600.00000\n",
      "eval d4rl score: 59.87964\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:52:54\n",
      "num of updates: 133000\n",
      "action loss: 0.05271\n",
      "eval avg reward: 621.00000\n",
      "eval avg ep len: 621.00000\n",
      "eval d4rl score: 61.98596\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:53:30\n",
      "num of updates: 134000\n",
      "action loss: 0.05276\n",
      "eval avg reward: 567.00000\n",
      "eval avg ep len: 567.00000\n",
      "eval d4rl score: 56.56971\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:54:06\n",
      "num of updates: 135000\n",
      "action loss: 0.05348\n",
      "eval avg reward: 597.00000\n",
      "eval avg ep len: 597.00000\n",
      "eval d4rl score: 59.57874\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:54:40\n",
      "num of updates: 136000\n",
      "action loss: 0.05440\n",
      "eval avg reward: 540.00000\n",
      "eval avg ep len: 540.00000\n",
      "eval d4rl score: 53.86158\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:55:20\n",
      "num of updates: 137000\n",
      "action loss: 0.05412\n",
      "eval avg reward: 683.00000\n",
      "eval avg ep len: 683.00000\n",
      "eval d4rl score: 68.20461\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:56:00\n",
      "num of updates: 138000\n",
      "action loss: 0.05314\n",
      "eval avg reward: 672.00000\n",
      "eval avg ep len: 672.00000\n",
      "eval d4rl score: 67.10130\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:56:40\n",
      "num of updates: 139000\n",
      "action loss: 0.05458\n",
      "eval avg reward: 681.00000\n",
      "eval avg ep len: 681.00000\n",
      "eval d4rl score: 68.00401\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:57:29\n",
      "num of updates: 140000\n",
      "action loss: 0.05362\n",
      "eval avg reward: 1000.00000\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 100.00000\n",
      "max d4rl score: 100.00000\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:58:04\n",
      "num of updates: 141000\n",
      "action loss: 0.05569\n",
      "eval avg reward: 616.00000\n",
      "eval avg ep len: 616.00000\n",
      "eval d4rl score: 61.48445\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:58:51\n",
      "num of updates: 142000\n",
      "action loss: 0.05433\n",
      "eval avg reward: 1000.00000\n",
      "eval avg ep len: 1000.00000\n",
      "eval d4rl score: 100.00000\n",
      "max d4rl score: 100.00000\n",
      "saving max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 0:59:30\n",
      "num of updates: 143000\n",
      "action loss: 0.05445\n",
      "eval avg reward: 733.00000\n",
      "eval avg ep len: 733.00000\n",
      "eval d4rl score: 73.21966\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:00:10\n",
      "num of updates: 144000\n",
      "action loss: 0.05482\n",
      "eval avg reward: 764.00000\n",
      "eval avg ep len: 764.00000\n",
      "eval d4rl score: 76.32899\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:00:47\n",
      "num of updates: 145000\n",
      "action loss: 0.05338\n",
      "eval avg reward: 666.00000\n",
      "eval avg ep len: 666.00000\n",
      "eval d4rl score: 66.49950\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:01:27\n",
      "num of updates: 146000\n",
      "action loss: 0.05241\n",
      "eval avg reward: 673.00000\n",
      "eval avg ep len: 673.00000\n",
      "eval d4rl score: 67.20160\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:02:04\n",
      "num of updates: 147000\n",
      "action loss: 0.05548\n",
      "eval avg reward: 600.00000\n",
      "eval avg ep len: 600.00000\n",
      "eval d4rl score: 59.87964\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:02:39\n",
      "num of updates: 148000\n",
      "action loss: 0.05331\n",
      "eval avg reward: 604.00000\n",
      "eval avg ep len: 604.00000\n",
      "eval d4rl score: 60.28084\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:03:16\n",
      "num of updates: 149000\n",
      "action loss: 0.05316\n",
      "eval avg reward: 636.00000\n",
      "eval avg ep len: 636.00000\n",
      "eval d4rl score: 63.49047\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:03:52\n",
      "num of updates: 150000\n",
      "action loss: 0.05328\n",
      "eval avg reward: 609.00000\n",
      "eval avg ep len: 609.00000\n",
      "eval d4rl score: 60.78235\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:04:27\n",
      "num of updates: 151000\n",
      "action loss: 0.05446\n",
      "eval avg reward: 575.00000\n",
      "eval avg ep len: 575.00000\n",
      "eval d4rl score: 57.37212\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:05:01\n",
      "num of updates: 152000\n",
      "action loss: 0.05412\n",
      "eval avg reward: 580.00000\n",
      "eval avg ep len: 580.00000\n",
      "eval d4rl score: 57.87362\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:05:25\n",
      "num of updates: 153000\n",
      "action loss: 0.05451\n",
      "eval avg reward: 236.00000\n",
      "eval avg ep len: 236.00000\n",
      "eval d4rl score: 23.37011\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:06:00\n",
      "num of updates: 154000\n",
      "action loss: 0.05400\n",
      "eval avg reward: 604.00000\n",
      "eval avg ep len: 604.00000\n",
      "eval d4rl score: 60.28084\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:06:35\n",
      "num of updates: 155000\n",
      "action loss: 0.05329\n",
      "eval avg reward: 573.00000\n",
      "eval avg ep len: 573.00000\n",
      "eval d4rl score: 57.17151\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:07:09\n",
      "num of updates: 156000\n",
      "action loss: 0.05316\n",
      "eval avg reward: 575.00000\n",
      "eval avg ep len: 575.00000\n",
      "eval d4rl score: 57.37212\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:07:44\n",
      "num of updates: 157000\n",
      "action loss: 0.05418\n",
      "eval avg reward: 584.00000\n",
      "eval avg ep len: 584.00000\n",
      "eval d4rl score: 58.27482\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:08:17\n",
      "num of updates: 158000\n",
      "action loss: 0.05457\n",
      "eval avg reward: 539.00000\n",
      "eval avg ep len: 539.00000\n",
      "eval d4rl score: 53.76128\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:08:51\n",
      "num of updates: 159000\n",
      "action loss: 0.05476\n",
      "eval avg reward: 601.00000\n",
      "eval avg ep len: 601.00000\n",
      "eval d4rl score: 59.97994\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:09:24\n",
      "num of updates: 160000\n",
      "action loss: 0.05363\n",
      "eval avg reward: 541.00000\n",
      "eval avg ep len: 541.00000\n",
      "eval d4rl score: 53.96189\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:10:01\n",
      "num of updates: 161000\n",
      "action loss: 0.05405\n",
      "eval avg reward: 626.00000\n",
      "eval avg ep len: 626.00000\n",
      "eval d4rl score: 62.48746\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:10:36\n",
      "num of updates: 162000\n",
      "action loss: 0.05364\n",
      "eval avg reward: 568.00000\n",
      "eval avg ep len: 568.00000\n",
      "eval d4rl score: 56.67001\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:11:12\n",
      "num of updates: 163000\n",
      "action loss: 0.05340\n",
      "eval avg reward: 625.00000\n",
      "eval avg ep len: 625.00000\n",
      "eval d4rl score: 62.38716\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:11:50\n",
      "num of updates: 164000\n",
      "action loss: 0.05253\n",
      "eval avg reward: 645.00000\n",
      "eval avg ep len: 645.00000\n",
      "eval d4rl score: 64.39318\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:12:24\n",
      "num of updates: 165000\n",
      "action loss: 0.05449\n",
      "eval avg reward: 568.00000\n",
      "eval avg ep len: 568.00000\n",
      "eval d4rl score: 56.67001\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:13:00\n",
      "num of updates: 166000\n",
      "action loss: 0.05302\n",
      "eval avg reward: 582.00000\n",
      "eval avg ep len: 582.00000\n",
      "eval d4rl score: 58.07422\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:13:39\n",
      "num of updates: 167000\n",
      "action loss: 0.05502\n",
      "eval avg reward: 674.00000\n",
      "eval avg ep len: 674.00000\n",
      "eval d4rl score: 67.30191\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:14:17\n",
      "num of updates: 168000\n",
      "action loss: 0.05513\n",
      "eval avg reward: 661.00000\n",
      "eval avg ep len: 661.00000\n",
      "eval d4rl score: 65.99799\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:14:52\n",
      "num of updates: 169000\n",
      "action loss: 0.05484\n",
      "eval avg reward: 596.00000\n",
      "eval avg ep len: 596.00000\n",
      "eval d4rl score: 59.47844\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:15:28\n",
      "num of updates: 170000\n",
      "action loss: 0.05407\n",
      "eval avg reward: 590.00000\n",
      "eval avg ep len: 590.00000\n",
      "eval d4rl score: 58.87663\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:16:06\n",
      "num of updates: 171000\n",
      "action loss: 0.05442\n",
      "eval avg reward: 689.00000\n",
      "eval avg ep len: 689.00000\n",
      "eval d4rl score: 68.80642\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:16:40\n",
      "num of updates: 172000\n",
      "action loss: 0.05330\n",
      "eval avg reward: 578.00000\n",
      "eval avg ep len: 578.00000\n",
      "eval d4rl score: 57.67302\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:17:15\n",
      "num of updates: 173000\n",
      "action loss: 0.05426\n",
      "eval avg reward: 603.00000\n",
      "eval avg ep len: 603.00000\n",
      "eval d4rl score: 60.18054\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:17:50\n",
      "num of updates: 174000\n",
      "action loss: 0.05483\n",
      "eval avg reward: 612.00000\n",
      "eval avg ep len: 612.00000\n",
      "eval d4rl score: 61.08325\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:18:27\n",
      "num of updates: 175000\n",
      "action loss: 0.05389\n",
      "eval avg reward: 647.00000\n",
      "eval avg ep len: 647.00000\n",
      "eval d4rl score: 64.59378\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:19:01\n",
      "num of updates: 176000\n",
      "action loss: 0.05322\n",
      "eval avg reward: 576.00000\n",
      "eval avg ep len: 576.00000\n",
      "eval d4rl score: 57.47242\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:19:38\n",
      "num of updates: 177000\n",
      "action loss: 0.05340\n",
      "eval avg reward: 622.00000\n",
      "eval avg ep len: 622.00000\n",
      "eval d4rl score: 62.08626\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:20:13\n",
      "num of updates: 178000\n",
      "action loss: 0.05600\n",
      "eval avg reward: 540.00000\n",
      "eval avg ep len: 540.00000\n",
      "eval d4rl score: 53.86158\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:20:50\n",
      "num of updates: 179000\n",
      "action loss: 0.05329\n",
      "eval avg reward: 632.00000\n",
      "eval avg ep len: 632.00000\n",
      "eval d4rl score: 63.08927\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:21:24\n",
      "num of updates: 180000\n",
      "action loss: 0.05408\n",
      "eval avg reward: 552.00000\n",
      "eval avg ep len: 552.00000\n",
      "eval d4rl score: 55.06520\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:22:02\n",
      "num of updates: 181000\n",
      "action loss: 0.05340\n",
      "eval avg reward: 699.00000\n",
      "eval avg ep len: 699.00000\n",
      "eval d4rl score: 69.80943\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:22:37\n",
      "num of updates: 182000\n",
      "action loss: 0.05371\n",
      "eval avg reward: 571.00000\n",
      "eval avg ep len: 571.00000\n",
      "eval d4rl score: 56.97091\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:23:15\n",
      "num of updates: 183000\n",
      "action loss: 0.05500\n",
      "eval avg reward: 668.00000\n",
      "eval avg ep len: 668.00000\n",
      "eval d4rl score: 66.70010\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:23:51\n",
      "num of updates: 184000\n",
      "action loss: 0.05411\n",
      "eval avg reward: 583.00000\n",
      "eval avg ep len: 583.00000\n",
      "eval d4rl score: 58.17452\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:24:35\n",
      "num of updates: 185000\n",
      "action loss: 0.05340\n",
      "eval avg reward: 846.00000\n",
      "eval avg ep len: 846.00000\n",
      "eval d4rl score: 84.55366\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:25:10\n",
      "num of updates: 186000\n",
      "action loss: 0.05451\n",
      "eval avg reward: 552.00000\n",
      "eval avg ep len: 552.00000\n",
      "eval d4rl score: 55.06520\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:25:47\n",
      "num of updates: 187000\n",
      "action loss: 0.05260\n",
      "eval avg reward: 591.00000\n",
      "eval avg ep len: 591.00000\n",
      "eval d4rl score: 58.97693\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:26:20\n",
      "num of updates: 188000\n",
      "action loss: 0.05529\n",
      "eval avg reward: 553.00000\n",
      "eval avg ep len: 553.00000\n",
      "eval d4rl score: 55.16550\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:26:54\n",
      "num of updates: 189000\n",
      "action loss: 0.05400\n",
      "eval avg reward: 585.00000\n",
      "eval avg ep len: 585.00000\n",
      "eval d4rl score: 58.37513\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:27:28\n",
      "num of updates: 190000\n",
      "action loss: 0.05526\n",
      "eval avg reward: 569.00000\n",
      "eval avg ep len: 569.00000\n",
      "eval d4rl score: 56.77031\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:28:01\n",
      "num of updates: 191000\n",
      "action loss: 0.05335\n",
      "eval avg reward: 553.00000\n",
      "eval avg ep len: 553.00000\n",
      "eval d4rl score: 55.16550\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:28:35\n",
      "num of updates: 192000\n",
      "action loss: 0.05331\n",
      "eval avg reward: 567.00000\n",
      "eval avg ep len: 567.00000\n",
      "eval d4rl score: 56.56971\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:29:09\n",
      "num of updates: 193000\n",
      "action loss: 0.05360\n",
      "eval avg reward: 565.00000\n",
      "eval avg ep len: 565.00000\n",
      "eval d4rl score: 56.36911\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:29:43\n",
      "num of updates: 194000\n",
      "action loss: 0.05436\n",
      "eval avg reward: 572.00000\n",
      "eval avg ep len: 572.00000\n",
      "eval d4rl score: 57.07121\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:30:17\n",
      "num of updates: 195000\n",
      "action loss: 0.05509\n",
      "eval avg reward: 552.00000\n",
      "eval avg ep len: 552.00000\n",
      "eval d4rl score: 55.06520\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:30:54\n",
      "num of updates: 196000\n",
      "action loss: 0.05526\n",
      "eval avg reward: 627.00000\n",
      "eval avg ep len: 627.00000\n",
      "eval d4rl score: 62.58776\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:31:29\n",
      "num of updates: 197000\n",
      "action loss: 0.05414\n",
      "eval avg reward: 547.00000\n",
      "eval avg ep len: 547.00000\n",
      "eval d4rl score: 54.56369\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:32:03\n",
      "num of updates: 198000\n",
      "action loss: 0.05326\n",
      "eval avg reward: 567.00000\n",
      "eval avg ep len: 567.00000\n",
      "eval d4rl score: 56.56971\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:32:36\n",
      "num of updates: 199000\n",
      "action loss: 0.05405\n",
      "eval avg reward: 509.00000\n",
      "eval avg ep len: 509.00000\n",
      "eval d4rl score: 50.75226\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "time elapsed: 1:33:10\n",
      "num of updates: 200000\n",
      "action loss: 0.05275\n",
      "eval avg reward: 576.00000\n",
      "eval avg ep len: 576.00000\n",
      "eval d4rl score: 57.47242\n",
      "max d4rl score: 100.00000\n",
      "saving current model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n",
      "finished training!\n",
      "============================================================\n",
      "started training at: 24-11-23-09-03-41\n",
      "finished training at: 24-11-23-10-36-51\n",
      "total training time: 1:33:10\n",
      "max d4rl score: 100.00000\n",
      "saved max d4rl score model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41_best.pt\n",
      "saved last updated model at: ./dt_runs/dt_InvertedPendulum-v4-stitched_model_24-11-23-09-03-41.pt\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "\n",
    "start_time_str = start_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "prefix = \"dt_\" + env_d4rl_name\n",
    "\n",
    "save_model_name =  prefix + \"_model_\" + start_time_str + \".pt\"\n",
    "save_model_path = os.path.join(log_dir, save_model_name)\n",
    "save_best_model_path = save_model_path[:-3] + \"_best.pt\"\n",
    "\n",
    "log_csv_name = prefix + \"_log_\" + start_time_str + \".csv\"\n",
    "log_csv_path = os.path.join(log_dir, log_csv_name)\n",
    "\n",
    "\n",
    "csv_writer = csv.writer(open(log_csv_path, 'a', 1))\n",
    "csv_header = ([\"duration\", \"num_updates\", \"action_loss\",\n",
    "               \"eval_avg_reward\", \"eval_avg_ep_len\", \"eval_d4rl_score\"])\n",
    "\n",
    "csv_writer.writerow(csv_header)\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"start time: \" + start_time_str)\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"device set to: \" + str(device))\n",
    "print(\"dataset path: \" + dataset_path)\n",
    "print(\"model save path: \" + save_model_path)\n",
    "print(\"log csv save path: \" + log_csv_path)\n",
    "\n",
    "\n",
    "traj_dataset = D4RLTrajectoryDataset(dataset_path, context_len, rtg_scale)\n",
    "\n",
    "traj_data_loader = DataLoader(traj_dataset,\n",
    "\t\t\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\t\t\tshuffle=True,\n",
    "\t\t\t\t\t\tpin_memory=True,\n",
    "\t\t\t\t\t\tdrop_last=True)\n",
    "\n",
    "data_iter = iter(traj_data_loader)\n",
    "\n",
    "## get state stats from dataset\n",
    "state_mean, state_std = traj_dataset.get_state_stats()\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "act_dim = env.action_space.shape[0]\n",
    "\n",
    "model = DecisionTransformer(\n",
    "\t\t\tstate_dim=state_dim,\n",
    "\t\t\tact_dim=act_dim,\n",
    "\t\t\tn_blocks=n_blocks,\n",
    "\t\t\th_dim=embed_dim,\n",
    "\t\t\tcontext_len=context_len,\n",
    "\t\t\tn_heads=n_heads,\n",
    "\t\t\tdrop_p=dropout_p,\n",
    "\t\t).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "\t\t\t\t\tmodel.parameters(),\n",
    "\t\t\t\t\tlr=lr,\n",
    "\t\t\t\t\tweight_decay=wt_decay\n",
    "\t\t\t\t)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(\n",
    "\t\toptimizer,\n",
    "\t\tlambda steps: min((steps+1)/warmup_steps, 1)\n",
    "\t)\n",
    "\n",
    "max_d4rl_score = -1.0\n",
    "total_updates = 0\n",
    "\n",
    "for i_train_iter in range(max_train_iters):\n",
    "\n",
    "\tlog_action_losses = []\n",
    "\tmodel.train()\n",
    "\n",
    "\tfor _ in range(num_updates_per_iter):\n",
    "\t\ttry:\n",
    "\t\t\ttimesteps, states, actions, returns_to_go, traj_mask = next(data_iter)\n",
    "\t\texcept StopIteration:\n",
    "\t\t\tdata_iter = iter(traj_data_loader)\n",
    "\t\t\ttimesteps, states, actions, returns_to_go, traj_mask = next(data_iter)\n",
    "\n",
    "\t\ttimesteps = timesteps.to(device)\t# B x T\n",
    "\t\tstates = states.to(device)\t\t\t# B x T x state_dim\n",
    "\t\tactions = actions.to(device)\t\t# B x T x act_dim\n",
    "\t\treturns_to_go = returns_to_go.to(device).unsqueeze(dim=-1) # B x T x 1\n",
    "\t\ttraj_mask = traj_mask.to(device)\t# B x T\n",
    "\n",
    "\t\taction_target = torch.clone(actions).detach().to(device)\n",
    "\n",
    "\t\tstate_preds, action_preds, return_preds = model.forward(\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\ttimesteps=timesteps,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tstates=states,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\tactions=actions,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\treturns_to_go=returns_to_go\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t)\n",
    "\n",
    "\t\t# only consider non padded elements\n",
    "\t\taction_preds = action_preds.view(-1, act_dim)[traj_mask.view(-1,) > 0]\n",
    "\t\taction_target = action_target.view(-1, act_dim)[traj_mask.view(-1,) > 0]\n",
    "\n",
    "\t\taction_loss = F.mse_loss(action_preds, action_target, reduction='mean')\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\taction_loss.backward()\n",
    "\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), 0.25)\n",
    "\t\toptimizer.step()\n",
    "\t\tscheduler.step()\n",
    "\n",
    "\t\tlog_action_losses.append(action_loss.detach().cpu().item())\n",
    "\n",
    "\t# evaluate on env\n",
    "\tresults = evaluate_on_env(model, device, context_len, env, rtg_target, rtg_scale,\n",
    "\t                        num_eval_ep, max_eval_ep_len, state_mean, state_std,\n",
    "\t\t\t\t\t\t\t)\n",
    "\teval_avg_reward = results['eval/avg_reward']\n",
    "\teval_avg_ep_len = results['eval/avg_ep_len']\n",
    "\teval_d4rl_score = get_d4rl_normalized_score(results['eval/avg_reward'], env_name) * 100\n",
    "\n",
    "\tmean_action_loss = np.mean(log_action_losses)\n",
    "\ttime_elapsed = str(datetime.now().replace(microsecond=0) - start_time)\n",
    "\n",
    "\ttotal_updates += num_updates_per_iter\n",
    "\n",
    "\tlog_str = (\"=\" * 60 + '\\n' +\n",
    "\t\t\t\"time elapsed: \" + time_elapsed  + '\\n' +\n",
    "\t\t\t\"num of updates: \" + str(total_updates) + '\\n' +\n",
    "\t\t\t\"action loss: \" +  format(mean_action_loss, \".5f\") + '\\n' +\n",
    "\t\t\t\"eval avg reward: \" + format(eval_avg_reward, \".5f\") + '\\n' +\n",
    "\t\t\t\"eval avg ep len: \" + format(eval_avg_ep_len, \".5f\") + '\\n' +\n",
    "\t\t\t\"eval d4rl score: \" + format(eval_d4rl_score, \".5f\")\n",
    "\t\t\t)\n",
    "\n",
    "\tprint(log_str)\n",
    "\n",
    "\tlog_data = [time_elapsed, total_updates, mean_action_loss,\n",
    "\t\t\t\teval_avg_reward, eval_avg_ep_len,\n",
    "\t\t\t\teval_d4rl_score]\n",
    "\n",
    "\tcsv_writer.writerow(log_data)\n",
    "\n",
    "\t# save model\n",
    "\tprint(\"max d4rl score: \" + format(max_d4rl_score, \".5f\"))\n",
    "\tif eval_d4rl_score >= max_d4rl_score:\n",
    "\t\tprint(\"saving max d4rl score model at: \" + save_best_model_path)\n",
    "\t\ttorch.save(model.state_dict(), save_best_model_path)\n",
    "\t\tmax_d4rl_score = eval_d4rl_score\n",
    "\n",
    "\tprint(\"saving current model at: \" + save_model_path)\n",
    "\ttorch.save(model.state_dict(), save_model_path)\n",
    "\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"finished training!\")\n",
    "print(\"=\" * 60)\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "time_elapsed = str(end_time - start_time)\n",
    "end_time_str = end_time.strftime(\"%y-%m-%d-%H-%M-%S\")\n",
    "print(\"started training at: \" + start_time_str)\n",
    "print(\"finished training at: \" + end_time_str)\n",
    "print(\"total training time: \" + time_elapsed)\n",
    "print(\"max d4rl score: \" + format(max_d4rl_score, \".5f\"))\n",
    "print(\"saved max d4rl score model at: \" + save_best_model_path)\n",
    "print(\"saved last updated model at: \" + save_model_path)\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjBsdz9mKbZg"
   },
   "source": [
    "# plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "2WM69ti2KaRN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt_runs/dt_InvertedPendulum-v4-stitched_log_24-11-22-22-35-34.csv (200, 6)\n",
      "dt_runs/dt_InvertedPendulum-v4-stitched_log_24-11-23-09-03-41.csv (200, 6)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "env_d4rl_name = 'InvertedPendulum-v4'\n",
    "log_dir = 'dt_runs/'\n",
    "\n",
    "x_key = \"num_updates\"\n",
    "y_key = \"eval_d4rl_score\"\n",
    "y_smoothing_win = 5\n",
    "plot_avg = False\n",
    "save_fig = False\n",
    "\n",
    "if plot_avg:\n",
    "    save_fig_path = env_d4rl_name + \"_avg.png\"\n",
    "else:\n",
    "    save_fig_path = env_d4rl_name + \".png\"\n",
    "\n",
    "\n",
    "all_files = glob.glob(log_dir + f'/dt_{env_d4rl_name}*.csv')\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_title(env_d4rl_name)\n",
    "\n",
    "if plot_avg:\n",
    "    name_list = []\n",
    "    df_list = []\n",
    "    for filename in all_files:\n",
    "        frame = pd.read_csv(filename, index_col=None, header=0)\n",
    "        print(filename, frame.shape)\n",
    "        frame['y_smooth'] = frame[y_key].rolling(window=y_smoothing_win).mean()\n",
    "        df_list.append(frame)\n",
    "\n",
    "\n",
    "    df_concat = pd.concat(df_list)\n",
    "    df_concat_groupby = df_concat.groupby(df_concat.index)\n",
    "    data_avg = df_concat_groupby.mean()\n",
    "\n",
    "    data_avg.plot(x=x_key, y='y_smooth', ax=ax)\n",
    "\n",
    "    ax.set_xlabel(x_key)\n",
    "    ax.set_ylabel(y_key)\n",
    "    # ax.legend(['avg of all runs'], loc='lower right')\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(save_fig_path)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "else:\n",
    "    name_list = []\n",
    "    for filename in all_files:\n",
    "        frame = pd.read_csv(filename, index_col=None, header=0)\n",
    "        print(filename, frame.shape)\n",
    "        frame['y_smooth'] = frame[y_key].rolling(window=y_smoothing_win).mean()\n",
    "        frame.plot(x=x_key, y='y_smooth', ax=ax)\n",
    "        name_list.append(filename.split('/')[-1])\n",
    "\n",
    "    ax.set_xlabel(x_key)\n",
    "    ax.set_ylabel(y_key)\n",
    "    # ax.legend(name_list, loc='lower right')\n",
    "\n",
    "    if save_fig:\n",
    "        plt.savefig(save_fig_path)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Euib_RmfOiT3",
    "aBD3fRknjEj6",
    "9TpGEYTblzQc",
    "wNJM0LG1iziA",
    "gLHjV3q28LNr",
    "pewE01Ca4BG0",
    "QXXrs_PjAHrN",
    "wxcJqnb1Him4"
   ],
   "name": "min_decision_transformer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "transformerdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
